<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 11 Function Approximation And Feature Engineering | Reinforcement Learning in R</title>
  <meta name="description" content="Chapter 11 Function Approximation And Feature Engineering | Reinforcement Learning in R" />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 11 Function Approximation And Feature Engineering | Reinforcement Learning in R" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 11 Function Approximation And Feature Engineering | Reinforcement Learning in R" />
  
  
  

<meta name="author" content="Kamran Afzalui" />


<meta name="date" content="2025-09-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html"/>
<link rel="next" href="learning-policies-versus-learning-values.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Reinforcement Learning in R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> <strong>Understanding Reinforcement Learning: From Bandits to Policy Optimization</strong></a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#introduction-to-reinforcement-learning"><i class="fa fa-check"></i><b>1.1</b> Introduction to Reinforcement Learning</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#the-multi-armed-bandit-the-simplest-case"><i class="fa fa-check"></i><b>1.2</b> The Multi-Armed Bandit: The Simplest Case</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#transition-to-markov-decision-processes"><i class="fa fa-check"></i><b>1.3</b> Transition to Markov Decision Processes</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#comparing-reinforcement-learning-methods"><i class="fa fa-check"></i><b>1.4</b> Comparing Reinforcement Learning Methods</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="index.html"><a href="index.html#dynamic-programming-model-based-learning"><i class="fa fa-check"></i><b>1.4.1</b> Dynamic Programming: Model-Based Learning</a></li>
<li class="chapter" data-level="1.4.2" data-path="index.html"><a href="index.html#model-free-approaches-monte-carlo-and-td-learning"><i class="fa fa-check"></i><b>1.4.2</b> Model-Free Approaches: Monte Carlo and TD Learning</a></li>
<li class="chapter" data-level="1.4.3" data-path="index.html"><a href="index.html#dyna-bridging-model-free-and-model-based-learning"><i class="fa fa-check"></i><b>1.4.3</b> Dyna: Bridging Model-Free and Model-Based Learning</a></li>
<li class="chapter" data-level="1.4.4" data-path="index.html"><a href="index.html#q-learning-and-function-approximation"><i class="fa fa-check"></i><b>1.4.4</b> Q-Learning and Function Approximation</a></li>
<li class="chapter" data-level="1.4.5" data-path="index.html"><a href="index.html#policy-gradient-and-actor-critic-methods"><i class="fa fa-check"></i><b>1.4.5</b> Policy Gradient and Actor-Critic Methods</a></li>
<li class="chapter" data-level="1.4.6" data-path="index.html"><a href="index.html#advanced-policy-optimization-techniques"><i class="fa fa-check"></i><b>1.4.6</b> Advanced Policy Optimization Techniques</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#further-directions"><i class="fa fa-check"></i><b>1.5</b> Further Directions</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#references"><i class="fa fa-check"></i><b>1.6</b> References</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="the-multi-armed-bandit-problem.html"><a href="the-multi-armed-bandit-problem.html"><i class="fa fa-check"></i><b>2</b> The Multi-Armed Bandit Problem</a>
<ul>
<li class="chapter" data-level="2.1" data-path="the-multi-armed-bandit-problem.html"><a href="the-multi-armed-bandit-problem.html#introduction"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="the-multi-armed-bandit-problem.html"><a href="the-multi-armed-bandit-problem.html#mathematical-formalism"><i class="fa fa-check"></i><b>2.2</b> Mathematical Formalism</a></li>
<li class="chapter" data-level="2.3" data-path="the-multi-armed-bandit-problem.html"><a href="the-multi-armed-bandit-problem.html#frequentist-approach-ucb1-algorithm"><i class="fa fa-check"></i><b>2.3</b> Frequentist Approach: UCB1 Algorithm</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="the-multi-armed-bandit-problem.html"><a href="the-multi-armed-bandit-problem.html#r-code-for-ucb1"><i class="fa fa-check"></i><b>2.3.1</b> R Code for UCB1</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="the-multi-armed-bandit-problem.html"><a href="the-multi-armed-bandit-problem.html#bayesian-approach-thompson-sampling"><i class="fa fa-check"></i><b>2.4</b> Bayesian Approach: Thompson Sampling</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="the-multi-armed-bandit-problem.html"><a href="the-multi-armed-bandit-problem.html#r-code-for-thompson-sampling"><i class="fa fa-check"></i><b>2.4.1</b> R Code for Thompson Sampling</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="the-multi-armed-bandit-problem.html"><a href="the-multi-armed-bandit-problem.html#epsilon-greedy-strategy"><i class="fa fa-check"></i><b>2.5</b> Epsilon-Greedy Strategy</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="the-multi-armed-bandit-problem.html"><a href="the-multi-armed-bandit-problem.html#r-code-for-epsilon-greedy"><i class="fa fa-check"></i><b>2.5.1</b> R Code for Epsilon-Greedy</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="the-multi-armed-bandit-problem.html"><a href="the-multi-armed-bandit-problem.html#summary-table"><i class="fa fa-check"></i><b>2.6</b> Summary Table</a></li>
<li class="chapter" data-level="2.7" data-path="the-multi-armed-bandit-problem.html"><a href="the-multi-armed-bandit-problem.html#conclusion"><i class="fa fa-check"></i><b>2.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="markov-decision-processes-and-dynamic-programming.html"><a href="markov-decision-processes-and-dynamic-programming.html"><i class="fa fa-check"></i><b>3</b> Markov Decision Processes and Dynamic Programming</a>
<ul>
<li class="chapter" data-level="3.1" data-path="markov-decision-processes-and-dynamic-programming.html"><a href="markov-decision-processes-and-dynamic-programming.html#introduction-1"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="markov-decision-processes-and-dynamic-programming.html"><a href="markov-decision-processes-and-dynamic-programming.html#constructing-the-mdp-in-r"><i class="fa fa-check"></i><b>3.2</b> Constructing the MDP in R</a></li>
<li class="chapter" data-level="3.3" data-path="markov-decision-processes-and-dynamic-programming.html"><a href="markov-decision-processes-and-dynamic-programming.html#value-iteration-algorithm"><i class="fa fa-check"></i><b>3.3</b> Value Iteration Algorithm</a></li>
<li class="chapter" data-level="3.4" data-path="markov-decision-processes-and-dynamic-programming.html"><a href="markov-decision-processes-and-dynamic-programming.html#evaluation-and-interpretation"><i class="fa fa-check"></i><b>3.4</b> Evaluation and Interpretation</a></li>
<li class="chapter" data-level="3.5" data-path="markov-decision-processes-and-dynamic-programming.html"><a href="markov-decision-processes-and-dynamic-programming.html#theoretical-properties-of-value-iteration"><i class="fa fa-check"></i><b>3.5</b> Theoretical Properties of Value Iteration</a></li>
<li class="chapter" data-level="3.6" data-path="markov-decision-processes-and-dynamic-programming.html"><a href="markov-decision-processes-and-dynamic-programming.html#summary-table-1"><i class="fa fa-check"></i><b>3.6</b> Summary Table</a></li>
<li class="chapter" data-level="3.7" data-path="markov-decision-processes-and-dynamic-programming.html"><a href="markov-decision-processes-and-dynamic-programming.html#conclusion-1"><i class="fa fa-check"></i><b>3.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html"><a href="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html"><i class="fa fa-check"></i><b>4</b> Model-Free Reinforcement Learning: Temporal Difference and Monte Carlo Methods in R</a>
<ul>
<li class="chapter" data-level="4.1" data-path="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html"><a href="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html#introduction-2"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html"><a href="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html#theoretical-background"><i class="fa fa-check"></i><b>4.2</b> Theoretical Background</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html"><a href="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html#temporal-difference-learning-q-learning"><i class="fa fa-check"></i><b>4.2.1</b> Temporal Difference Learning (Q-Learning)</a></li>
<li class="chapter" data-level="4.2.2" data-path="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html"><a href="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html#monte-carlo-methods"><i class="fa fa-check"></i><b>4.2.2</b> Monte Carlo Methods</a></li>
<li class="chapter" data-level="4.2.3" data-path="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html"><a href="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html#step-1-defining-the-environment-in-r"><i class="fa fa-check"></i><b>4.2.3</b> Step 1: Defining the Environment in R</a></li>
<li class="chapter" data-level="4.2.4" data-path="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html"><a href="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html#step-2-q-learning-implementation-in-r"><i class="fa fa-check"></i><b>4.2.4</b> Step 2: Q-Learning Implementation in R</a></li>
<li class="chapter" data-level="4.2.5" data-path="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html"><a href="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html#step-3-monte-carlo-every-visit-implementation"><i class="fa fa-check"></i><b>4.2.5</b> Step 3: Monte Carlo Every-Visit Implementation</a></li>
<li class="chapter" data-level="4.2.6" data-path="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html"><a href="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html#step-4-simulating-outcome-devaluation"><i class="fa fa-check"></i><b>4.2.6</b> Step 4: Simulating Outcome Devaluation</a></li>
<li class="chapter" data-level="4.2.7" data-path="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html"><a href="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html#step-5-comparing-policies-before-and-after-devaluation"><i class="fa fa-check"></i><b>4.2.7</b> Step 5: Comparing Policies Before and After Devaluation</a></li>
<li class="chapter" data-level="4.2.8" data-path="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html"><a href="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html#step-6-visualizing-the-policies"><i class="fa fa-check"></i><b>4.2.8</b> Step 6: Visualizing the Policies</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html"><a href="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html#interpretation-and-discussion"><i class="fa fa-check"></i><b>4.3</b> Interpretation and Discussion</a></li>
<li class="chapter" data-level="4.4" data-path="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html"><a href="model-free-reinforcement-learning-temporal-difference-and-monte-carlo-methods-in-r.html#conclusion-2"><i class="fa fa-check"></i><b>4.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="on-policy-vs-off-policy-reinforcement-learning-sarsa-q-learning-and-monte-carlo-in-r.html"><a href="on-policy-vs-off-policy-reinforcement-learning-sarsa-q-learning-and-monte-carlo-in-r.html"><i class="fa fa-check"></i><b>5</b> On-Policy vs Off-Policy Reinforcement Learning: SARSA, Q-Learning, and Monte Carlo in R</a>
<ul>
<li class="chapter" data-level="5.1" data-path="on-policy-vs-off-policy-reinforcement-learning-sarsa-q-learning-and-monte-carlo-in-r.html"><a href="on-policy-vs-off-policy-reinforcement-learning-sarsa-q-learning-and-monte-carlo-in-r.html#introduction-3"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="on-policy-vs-off-policy-reinforcement-learning-sarsa-q-learning-and-monte-carlo-in-r.html"><a href="on-policy-vs-off-policy-reinforcement-learning-sarsa-q-learning-and-monte-carlo-in-r.html#sarsa-on-policy"><i class="fa fa-check"></i><b>5.2</b> SARSA (On-Policy)</a></li>
<li class="chapter" data-level="5.3" data-path="on-policy-vs-off-policy-reinforcement-learning-sarsa-q-learning-and-monte-carlo-in-r.html"><a href="on-policy-vs-off-policy-reinforcement-learning-sarsa-q-learning-and-monte-carlo-in-r.html#q-learning-off-policy"><i class="fa fa-check"></i><b>5.3</b> Q-Learning (Off-Policy)</a></li>
<li class="chapter" data-level="5.4" data-path="on-policy-vs-off-policy-reinforcement-learning-sarsa-q-learning-and-monte-carlo-in-r.html"><a href="on-policy-vs-off-policy-reinforcement-learning-sarsa-q-learning-and-monte-carlo-in-r.html#off-policy-monte-carlo-with-importance-sampling"><i class="fa fa-check"></i><b>5.4</b> Off-Policy Monte Carlo with Importance Sampling</a></li>
<li class="chapter" data-level="5.5" data-path="on-policy-vs-off-policy-reinforcement-learning-sarsa-q-learning-and-monte-carlo-in-r.html"><a href="on-policy-vs-off-policy-reinforcement-learning-sarsa-q-learning-and-monte-carlo-in-r.html#key-differences"><i class="fa fa-check"></i><b>5.5</b> Key Differences</a></li>
<li class="chapter" data-level="5.6" data-path="on-policy-vs-off-policy-reinforcement-learning-sarsa-q-learning-and-monte-carlo-in-r.html"><a href="on-policy-vs-off-policy-reinforcement-learning-sarsa-q-learning-and-monte-carlo-in-r.html#interpretation-and-discussion-1"><i class="fa fa-check"></i><b>5.6</b> Interpretation and Discussion</a></li>
<li class="chapter" data-level="5.7" data-path="on-policy-vs-off-policy-reinforcement-learning-sarsa-q-learning-and-monte-carlo-in-r.html"><a href="on-policy-vs-off-policy-reinforcement-learning-sarsa-q-learning-and-monte-carlo-in-r.html#conclusion-3"><i class="fa fa-check"></i><b>5.7</b> Conclusion</a></li>
<li class="chapter" data-level="5.8" data-path="on-policy-vs-off-policy-reinforcement-learning-sarsa-q-learning-and-monte-carlo-in-r.html"><a href="on-policy-vs-off-policy-reinforcement-learning-sarsa-q-learning-and-monte-carlo-in-r.html#comparison-table"><i class="fa fa-check"></i><b>5.8</b> Comparison Table</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="function-approximation-in-reinforcement-learning-q-learning-with-linear-models-in-r.html"><a href="function-approximation-in-reinforcement-learning-q-learning-with-linear-models-in-r.html"><i class="fa fa-check"></i><b>6</b> Function Approximation in Reinforcement Learning: Q-Learning with Linear Models in R</a>
<ul>
<li class="chapter" data-level="6.1" data-path="function-approximation-in-reinforcement-learning-q-learning-with-linear-models-in-r.html"><a href="function-approximation-in-reinforcement-learning-q-learning-with-linear-models-in-r.html#introduction-4"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="function-approximation-in-reinforcement-learning-q-learning-with-linear-models-in-r.html"><a href="function-approximation-in-reinforcement-learning-q-learning-with-linear-models-in-r.html#theoretical-background-1"><i class="fa fa-check"></i><b>6.2</b> Theoretical Background</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="function-approximation-in-reinforcement-learning-q-learning-with-linear-models-in-r.html"><a href="function-approximation-in-reinforcement-learning-q-learning-with-linear-models-in-r.html#q-learning-with-function-approximation"><i class="fa fa-check"></i><b>6.2.1</b> Q-Learning with Function Approximation</a></li>
<li class="chapter" data-level="6.2.2" data-path="function-approximation-in-reinforcement-learning-q-learning-with-linear-models-in-r.html"><a href="function-approximation-in-reinforcement-learning-q-learning-with-linear-models-in-r.html#comparison-with-tabular-q-learning"><i class="fa fa-check"></i><b>6.2.2</b> Comparison with Tabular Q-Learning</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="function-approximation-in-reinforcement-learning-q-learning-with-linear-models-in-r.html"><a href="function-approximation-in-reinforcement-learning-q-learning-with-linear-models-in-r.html#r-implementation"><i class="fa fa-check"></i><b>6.3</b> R Implementation</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html"><a href="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html"><i class="fa fa-check"></i><b>7</b> Beyond Linear Models: Q-Learning with Random Forest Function Approximation in R</a>
<ul>
<li class="chapter" data-level="7.1" data-path="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html"><a href="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html#introduction-5"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html"><a href="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html#theoretical-background-2"><i class="fa fa-check"></i><b>7.2</b> Theoretical Background</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html"><a href="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html#q-learning-with-random-forest-approximation"><i class="fa fa-check"></i><b>7.2.1</b> Q-Learning with Random Forest Approximation</a></li>
<li class="chapter" data-level="7.2.2" data-path="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html"><a href="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html#feature-engineering-for-tree-based-models"><i class="fa fa-check"></i><b>7.2.2</b> Feature Engineering for Tree-Based Models</a></li>
<li class="chapter" data-level="7.2.3" data-path="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html"><a href="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html#comparison-with-previous-methods"><i class="fa fa-check"></i><b>7.2.3</b> Comparison with Previous Methods</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html"><a href="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html#r-implementation-1"><i class="fa fa-check"></i><b>7.3</b> R Implementation</a></li>
<li class="chapter" data-level="7.4" data-path="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html"><a href="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html#analysis-and-insights"><i class="fa fa-check"></i><b>7.4</b> Analysis and Insights</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html"><a href="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html#policy-learning-characteristics"><i class="fa fa-check"></i><b>7.4.1</b> Policy Learning Characteristics</a></li>
<li class="chapter" data-level="7.4.2" data-path="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html"><a href="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html#computational-considerations"><i class="fa fa-check"></i><b>7.4.2</b> Computational Considerations</a></li>
<li class="chapter" data-level="7.4.3" data-path="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html"><a href="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html#feature-importance-insights"><i class="fa fa-check"></i><b>7.4.3</b> Feature Importance Insights</a></li>
<li class="chapter" data-level="7.4.4" data-path="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html"><a href="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html#practical-implications-1"><i class="fa fa-check"></i><b>7.4.4</b> Practical Implications</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html"><a href="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html#comparison-with-linear-approximation"><i class="fa fa-check"></i><b>7.5</b> Comparison with Linear Approximation</a></li>
<li class="chapter" data-level="7.6" data-path="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html"><a href="beyond-linear-models-q-learning-with-random-forest-function-approximation-in-r.html#conclusion-4"><i class="fa fa-check"></i><b>7.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="deep-function-approximation-q-learning-with-neural-networks-in-r.html"><a href="deep-function-approximation-q-learning-with-neural-networks-in-r.html"><i class="fa fa-check"></i><b>8</b> Deep Function Approximation: Q-Learning with Neural Networks in R</a>
<ul>
<li class="chapter" data-level="8.1" data-path="deep-function-approximation-q-learning-with-neural-networks-in-r.html"><a href="deep-function-approximation-q-learning-with-neural-networks-in-r.html#introduction-6"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="deep-function-approximation-q-learning-with-neural-networks-in-r.html"><a href="deep-function-approximation-q-learning-with-neural-networks-in-r.html#theoretical-foundation"><i class="fa fa-check"></i><b>8.2</b> Theoretical Foundation</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="deep-function-approximation-q-learning-with-neural-networks-in-r.html"><a href="deep-function-approximation-q-learning-with-neural-networks-in-r.html#universal-approximation-and-expressivity"><i class="fa fa-check"></i><b>8.2.1</b> Universal Approximation and Expressivity</a></li>
<li class="chapter" data-level="8.2.2" data-path="deep-function-approximation-q-learning-with-neural-networks-in-r.html"><a href="deep-function-approximation-q-learning-with-neural-networks-in-r.html#gradient-based-learning"><i class="fa fa-check"></i><b>8.2.2</b> Gradient-Based Learning</a></li>
<li class="chapter" data-level="8.2.3" data-path="deep-function-approximation-q-learning-with-neural-networks-in-r.html"><a href="deep-function-approximation-q-learning-with-neural-networks-in-r.html#comparison-with-previous-approaches"><i class="fa fa-check"></i><b>8.2.3</b> Comparison with Previous Approaches</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="deep-function-approximation-q-learning-with-neural-networks-in-r.html"><a href="deep-function-approximation-q-learning-with-neural-networks-in-r.html#r-implementation-2"><i class="fa fa-check"></i><b>8.3</b> R Implementation</a></li>
<li class="chapter" data-level="8.4" data-path="deep-function-approximation-q-learning-with-neural-networks-in-r.html"><a href="deep-function-approximation-q-learning-with-neural-networks-in-r.html#analysis-and-interpretation"><i class="fa fa-check"></i><b>8.4</b> Analysis and Interpretation</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="deep-function-approximation-q-learning-with-neural-networks-in-r.html"><a href="deep-function-approximation-q-learning-with-neural-networks-in-r.html#learning-dynamics"><i class="fa fa-check"></i><b>8.4.1</b> Learning Dynamics</a></li>
<li class="chapter" data-level="8.4.2" data-path="deep-function-approximation-q-learning-with-neural-networks-in-r.html"><a href="deep-function-approximation-q-learning-with-neural-networks-in-r.html#function-representation"><i class="fa fa-check"></i><b>8.4.2</b> Function Representation</a></li>
<li class="chapter" data-level="8.4.3" data-path="deep-function-approximation-q-learning-with-neural-networks-in-r.html"><a href="deep-function-approximation-q-learning-with-neural-networks-in-r.html#generalization-properties"><i class="fa fa-check"></i><b>8.4.3</b> Generalization Properties</a></li>
<li class="chapter" data-level="8.4.4" data-path="deep-function-approximation-q-learning-with-neural-networks-in-r.html"><a href="deep-function-approximation-q-learning-with-neural-networks-in-r.html#training-stability"><i class="fa fa-check"></i><b>8.4.4</b> Training Stability</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="deep-function-approximation-q-learning-with-neural-networks-in-r.html"><a href="deep-function-approximation-q-learning-with-neural-networks-in-r.html#practical-considerations"><i class="fa fa-check"></i><b>8.5</b> Practical Considerations</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="deep-function-approximation-q-learning-with-neural-networks-in-r.html"><a href="deep-function-approximation-q-learning-with-neural-networks-in-r.html#architecture-selection"><i class="fa fa-check"></i><b>8.5.1</b> Architecture Selection</a></li>
<li class="chapter" data-level="8.5.2" data-path="deep-function-approximation-q-learning-with-neural-networks-in-r.html"><a href="deep-function-approximation-q-learning-with-neural-networks-in-r.html#training-frequency"><i class="fa fa-check"></i><b>8.5.2</b> Training Frequency</a></li>
<li class="chapter" data-level="8.5.3" data-path="deep-function-approximation-q-learning-with-neural-networks-in-r.html"><a href="deep-function-approximation-q-learning-with-neural-networks-in-r.html#regularization"><i class="fa fa-check"></i><b>8.5.3</b> Regularization</a></li>
<li class="chapter" data-level="8.5.4" data-path="deep-function-approximation-q-learning-with-neural-networks-in-r.html"><a href="deep-function-approximation-q-learning-with-neural-networks-in-r.html#initialization-and-convergence"><i class="fa fa-check"></i><b>8.5.4</b> Initialization and Convergence</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="deep-function-approximation-q-learning-with-neural-networks-in-r.html"><a href="deep-function-approximation-q-learning-with-neural-networks-in-r.html#comparison-across-function-approximation-methods"><i class="fa fa-check"></i><b>8.6</b> Comparison Across Function Approximation Methods</a></li>
<li class="chapter" data-level="8.7" data-path="deep-function-approximation-q-learning-with-neural-networks-in-r.html"><a href="deep-function-approximation-q-learning-with-neural-networks-in-r.html#future-directions"><i class="fa fa-check"></i><b>8.7</b> Future Directions</a></li>
<li class="chapter" data-level="8.8" data-path="deep-function-approximation-q-learning-with-neural-networks-in-r.html"><a href="deep-function-approximation-q-learning-with-neural-networks-in-r.html#conclusion-5"><i class="fa fa-check"></i><b>8.8</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="dyna-and-dynaq.html"><a href="dyna-and-dynaq.html"><i class="fa fa-check"></i><b>9</b> Dyna and DynaQ</a>
<ul>
<li class="chapter" data-level="9.1" data-path="dyna-and-dynaq.html"><a href="dyna-and-dynaq.html#introduction-7"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="dyna-and-dynaq.html"><a href="dyna-and-dynaq.html#theoretical-framework"><i class="fa fa-check"></i><b>9.2</b> Theoretical Framework</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="dyna-and-dynaq.html"><a href="dyna-and-dynaq.html#the-dyna-architecture"><i class="fa fa-check"></i><b>9.2.1</b> The Dyna Architecture</a></li>
<li class="chapter" data-level="9.2.2" data-path="dyna-and-dynaq.html"><a href="dyna-and-dynaq.html#model-representation"><i class="fa fa-check"></i><b>9.2.2</b> Model Representation</a></li>
<li class="chapter" data-level="9.2.3" data-path="dyna-and-dynaq.html"><a href="dyna-and-dynaq.html#convergence-properties"><i class="fa fa-check"></i><b>9.2.3</b> Convergence Properties</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="dyna-and-dynaq.html"><a href="dyna-and-dynaq.html#implementation-in-r"><i class="fa fa-check"></i><b>9.3</b> Implementation in R</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="dyna-and-dynaq.html"><a href="dyna-and-dynaq.html#environment-setup"><i class="fa fa-check"></i><b>9.3.1</b> Environment Setup</a></li>
<li class="chapter" data-level="9.3.2" data-path="dyna-and-dynaq.html"><a href="dyna-and-dynaq.html#dyna-q-implementation"><i class="fa fa-check"></i><b>9.3.2</b> Dyna-Q Implementation</a></li>
<li class="chapter" data-level="9.3.3" data-path="dyna-and-dynaq.html"><a href="dyna-and-dynaq.html#standard-q-learning-for-comparison"><i class="fa fa-check"></i><b>9.3.3</b> Standard Q-Learning for Comparison</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="dyna-and-dynaq.html"><a href="dyna-and-dynaq.html#experimental-analysis"><i class="fa fa-check"></i><b>9.4</b> Experimental Analysis</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="dyna-and-dynaq.html"><a href="dyna-and-dynaq.html#learning-efficiency-comparison"><i class="fa fa-check"></i><b>9.4.1</b> Learning Efficiency Comparison</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="dyna-and-dynaq.html"><a href="dyna-and-dynaq.html#discussion"><i class="fa fa-check"></i><b>9.5</b> Discussion</a></li>
<li class="chapter" data-level="9.6" data-path="dyna-and-dynaq.html"><a href="dyna-and-dynaq.html#implementation-considerations-and-conclusion"><i class="fa fa-check"></i><b>9.6</b> Implementation Considerations and Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html"><a href="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html"><i class="fa fa-check"></i><b>10</b> Dyna-Q+: Enhanced Exploration in Integrated Learning and Planning</a>
<ul>
<li class="chapter" data-level="10.1" data-path="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html"><a href="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html#introduction-8"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html"><a href="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html#theoretical-framework-1"><i class="fa fa-check"></i><b>10.2</b> Theoretical Framework</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html"><a href="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html#the-exploration-bonus-mechanism"><i class="fa fa-check"></i><b>10.2.1</b> The Exploration Bonus Mechanism</a></li>
<li class="chapter" data-level="10.2.2" data-path="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html"><a href="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html#complete-dyna-q-algorithm"><i class="fa fa-check"></i><b>10.2.2</b> Complete Dyna-Q+ Algorithm</a></li>
<li class="chapter" data-level="10.2.3" data-path="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html"><a href="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html#convergence-and-stability"><i class="fa fa-check"></i><b>10.2.3</b> Convergence and Stability</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html"><a href="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html#implementation-in-r-1"><i class="fa fa-check"></i><b>10.3</b> Implementation in R</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html"><a href="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html#environment-setup-1"><i class="fa fa-check"></i><b>10.3.1</b> Environment Setup</a></li>
<li class="chapter" data-level="10.3.2" data-path="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html"><a href="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html#dyna-q-implementation-1"><i class="fa fa-check"></i><b>10.3.2</b> Dyna-Q+ Implementation</a></li>
<li class="chapter" data-level="10.3.3" data-path="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html"><a href="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html#standard-dyna-for-comparison"><i class="fa fa-check"></i><b>10.3.3</b> Standard Dyna for Comparison</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html"><a href="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html#experimental-analysis-1"><i class="fa fa-check"></i><b>10.4</b> Experimental Analysis</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html"><a href="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html#adaptation-to-environmental-changes"><i class="fa fa-check"></i><b>10.4.1</b> Adaptation to Environmental Changes</a></li>
<li class="chapter" data-level="10.4.2" data-path="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html"><a href="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html#parameter-sensitivity-analysis"><i class="fa fa-check"></i><b>10.4.2</b> Parameter Sensitivity Analysis</a></li>
<li class="chapter" data-level="10.4.3" data-path="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html"><a href="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html#exploration-pattern-analysis"><i class="fa fa-check"></i><b>10.4.3</b> Exploration Pattern Analysis</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html"><a href="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html#discussion-and-implementation-considerations"><i class="fa fa-check"></i><b>10.5</b> Discussion and Implementation Considerations</a></li>
<li class="chapter" data-level="10.6" data-path="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html"><a href="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html#conclusion-6"><i class="fa fa-check"></i><b>10.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="function-approximation-and-feature-engineering.html"><a href="function-approximation-and-feature-engineering.html"><i class="fa fa-check"></i><b>11</b> Function Approximation And Feature Engineering</a>
<ul>
<li class="chapter" data-level="11.1" data-path="function-approximation-and-feature-engineering.html"><a href="function-approximation-and-feature-engineering.html#feature-engineering-and-state-representation"><i class="fa fa-check"></i><b>11.1</b> Feature Engineering and State Representation</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="function-approximation-and-feature-engineering.html"><a href="function-approximation-and-feature-engineering.html#the-discrimination-vs.-generalization-tradeoff"><i class="fa fa-check"></i><b>11.1.1</b> The Discrimination vs. Generalization Tradeoff</a></li>
<li class="chapter" data-level="11.1.2" data-path="function-approximation-and-feature-engineering.html"><a href="function-approximation-and-feature-engineering.html#principles-of-feature-extraction"><i class="fa fa-check"></i><b>11.1.2</b> Principles of Feature Extraction</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="function-approximation-and-feature-engineering.html"><a href="function-approximation-and-feature-engineering.html#mathematical-foundations-of-linear-function-approximation"><i class="fa fa-check"></i><b>11.2</b> Mathematical Foundations of Linear Function Approximation</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="function-approximation-and-feature-engineering.html"><a href="function-approximation-and-feature-engineering.html#linear-value-functions"><i class="fa fa-check"></i><b>11.2.1</b> Linear Value Functions</a></li>
<li class="chapter" data-level="11.2.2" data-path="function-approximation-and-feature-engineering.html"><a href="function-approximation-and-feature-engineering.html#temporal-difference-td-learning-with-function-approximation"><i class="fa fa-check"></i><b>11.2.2</b> Temporal Difference (TD) Learning with Function Approximation</a></li>
<li class="chapter" data-level="11.2.3" data-path="function-approximation-and-feature-engineering.html"><a href="function-approximation-and-feature-engineering.html#convergence-and-the-deadly-triad"><i class="fa fa-check"></i><b>11.2.3</b> Convergence and the “Deadly Triad”</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="function-approximation-and-feature-engineering.html"><a href="function-approximation-and-feature-engineering.html#classical-basis-function-methods"><i class="fa fa-check"></i><b>11.3</b> Classical Basis Function Methods</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="function-approximation-and-feature-engineering.html"><a href="function-approximation-and-feature-engineering.html#coarse-coding"><i class="fa fa-check"></i><b>11.3.1</b> Coarse Coding</a></li>
<li class="chapter" data-level="11.3.2" data-path="function-approximation-and-feature-engineering.html"><a href="function-approximation-and-feature-engineering.html#tile-coding"><i class="fa fa-check"></i><b>11.3.2</b> Tile Coding</a></li>
<li class="chapter" data-level="11.3.3" data-path="function-approximation-and-feature-engineering.html"><a href="function-approximation-and-feature-engineering.html#radial-basis-functions-rbfs"><i class="fa fa-check"></i><b>11.3.3</b> Radial Basis Functions (RBFs)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="learning-policies-versus-learning-values.html"><a href="learning-policies-versus-learning-values.html"><i class="fa fa-check"></i><b>12</b> Learning Policies versus Learning Values:</a>
<ul>
<li class="chapter" data-level="12.1" data-path="learning-policies-versus-learning-values.html"><a href="learning-policies-versus-learning-values.html#the-two-paradigms-of-reinforcement-learning"><i class="fa fa-check"></i><b>12.1</b> The Two Paradigms of Reinforcement Learning</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="learning-policies-versus-learning-values.html"><a href="learning-policies-versus-learning-values.html#value-based-methods-learning-worth-before-action"><i class="fa fa-check"></i><b>12.1.1</b> Value-Based Methods: Learning Worth Before Action</a></li>
<li class="chapter" data-level="12.1.2" data-path="learning-policies-versus-learning-values.html"><a href="learning-policies-versus-learning-values.html#policy-based-methods-direct-optimization-of-behavior"><i class="fa fa-check"></i><b>12.1.2</b> Policy-Based Methods: Direct Optimization of Behavior</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="average-reward-in-reinforcement-learning-a-comprehensive-guide.html"><a href="average-reward-in-reinforcement-learning-a-comprehensive-guide.html"><i class="fa fa-check"></i><b>13</b> Average Reward in Reinforcement Learning: A Comprehensive Guide</a>
<ul>
<li class="chapter" data-level="13.1" data-path="average-reward-in-reinforcement-learning-a-comprehensive-guide.html"><a href="average-reward-in-reinforcement-learning-a-comprehensive-guide.html#the-limitations-of-discounted-reward-formulations"><i class="fa fa-check"></i><b>13.1</b> The Limitations of Discounted Reward Formulations</a></li>
<li class="chapter" data-level="13.2" data-path="average-reward-in-reinforcement-learning-a-comprehensive-guide.html"><a href="average-reward-in-reinforcement-learning-a-comprehensive-guide.html#the-average-reward-alternative-theoretical-foundations"><i class="fa fa-check"></i><b>13.2</b> The Average Reward Alternative: Theoretical Foundations</a></li>
<li class="chapter" data-level="13.3" data-path="average-reward-in-reinforcement-learning-a-comprehensive-guide.html"><a href="average-reward-in-reinforcement-learning-a-comprehensive-guide.html#value-functions-in-the-average-reward-setting"><i class="fa fa-check"></i><b>13.3</b> Value Functions in the Average Reward Setting</a></li>
<li class="chapter" data-level="13.4" data-path="average-reward-in-reinforcement-learning-a-comprehensive-guide.html"><a href="average-reward-in-reinforcement-learning-a-comprehensive-guide.html#optimality-theory-for-average-reward"><i class="fa fa-check"></i><b>13.4</b> Optimality Theory for Average Reward</a></li>
<li class="chapter" data-level="13.5" data-path="average-reward-in-reinforcement-learning-a-comprehensive-guide.html"><a href="average-reward-in-reinforcement-learning-a-comprehensive-guide.html#learning-algorithms-for-average-reward"><i class="fa fa-check"></i><b>13.5</b> Learning Algorithms for Average Reward</a></li>
<li class="chapter" data-level="13.6" data-path="average-reward-in-reinforcement-learning-a-comprehensive-guide.html"><a href="average-reward-in-reinforcement-learning-a-comprehensive-guide.html#practical-implementation-server-load-balancing"><i class="fa fa-check"></i><b>13.6</b> Practical Implementation: Server Load Balancing</a></li>
<li class="chapter" data-level="13.7" data-path="average-reward-in-reinforcement-learning-a-comprehensive-guide.html"><a href="average-reward-in-reinforcement-learning-a-comprehensive-guide.html#implementation-considerations"><i class="fa fa-check"></i><b>13.7</b> Implementation Considerations</a></li>
<li class="chapter" data-level="13.8" data-path="average-reward-in-reinforcement-learning-a-comprehensive-guide.html"><a href="average-reward-in-reinforcement-learning-a-comprehensive-guide.html#when-to-choose-average-reward-over-discounting"><i class="fa fa-check"></i><b>13.8</b> When to Choose Average Reward Over Discounting</a></li>
<li class="chapter" data-level="13.9" data-path="average-reward-in-reinforcement-learning-a-comprehensive-guide.html"><a href="average-reward-in-reinforcement-learning-a-comprehensive-guide.html#appendix-a-mathematical-proofs-and-derivations"><i class="fa fa-check"></i><b>13.9</b> Appendix A: Mathematical Proofs and Derivations</a>
<ul>
<li class="chapter" data-level="13.9.1" data-path="average-reward-in-reinforcement-learning-a-comprehensive-guide.html"><a href="average-reward-in-reinforcement-learning-a-comprehensive-guide.html#convergence-of-average-reward-td-learning"><i class="fa fa-check"></i><b>13.9.1</b> Convergence of Average Reward TD Learning</a></li>
<li class="chapter" data-level="13.9.2" data-path="average-reward-in-reinforcement-learning-a-comprehensive-guide.html"><a href="average-reward-in-reinforcement-learning-a-comprehensive-guide.html#policy-gradient-theorem-for-average-reward"><i class="fa fa-check"></i><b>13.9.2</b> Policy Gradient Theorem for Average Reward</a></li>
<li class="chapter" data-level="13.9.3" data-path="average-reward-in-reinforcement-learning-a-comprehensive-guide.html"><a href="average-reward-in-reinforcement-learning-a-comprehensive-guide.html#optimality-equations-derivation"><i class="fa fa-check"></i><b>13.9.3</b> Optimality Equations Derivation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="eligibility-traces.html"><a href="eligibility-traces.html"><i class="fa fa-check"></i><b>14</b> Eligibility Traces</a>
<ul>
<li class="chapter" data-level="14.1" data-path="eligibility-traces.html"><a href="eligibility-traces.html#from-one-step-to-multi-step-learning"><i class="fa fa-check"></i><b>14.1</b> From One-Step to Multi-Step Learning</a></li>
<li class="chapter" data-level="14.2" data-path="eligibility-traces.html"><a href="eligibility-traces.html#the-mechanics-of-eligibility-traces-a-backward-view"><i class="fa fa-check"></i><b>14.2</b> The Mechanics of Eligibility Traces: A Backward View</a></li>
<li class="chapter" data-level="14.3" data-path="eligibility-traces.html"><a href="eligibility-traces.html#the-tdlambda-algorithm-for-prediction"><i class="fa fa-check"></i><b>14.3</b> The TD(<span class="math inline">\(\\lambda\)</span>) Algorithm for Prediction</a></li>
<li class="chapter" data-level="14.4" data-path="eligibility-traces.html"><a href="eligibility-traces.html#control-with-eligibility-traces-average-reward-sarsalambda"><i class="fa fa-check"></i><b>14.4</b> Control with Eligibility Traces: Average Reward Sarsa(<span class="math inline">\(\\lambda\)</span>)</a></li>
<li class="chapter" data-level="14.5" data-path="eligibility-traces.html"><a href="eligibility-traces.html#practical-implementation-server-load-balancing-with-sarsalambda"><i class="fa fa-check"></i><b>14.5</b> Practical Implementation: Server Load Balancing with Sarsa(<span class="math inline">\(\\lambda\)</span>)</a></li>
<li class="chapter" data-level="14.6" data-path="eligibility-traces.html"><a href="eligibility-traces.html#computational-and-performance-considerations"><i class="fa fa-check"></i><b>14.6</b> Computational and Performance Considerations</a></li>
<li class="chapter" data-level="14.7" data-path="eligibility-traces.html"><a href="eligibility-traces.html#conclusion-8"><i class="fa fa-check"></i><b>14.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="intrinsic-rewards.html"><a href="intrinsic-rewards.html"><i class="fa fa-check"></i><b>15</b> Intrinsic Rewards</a>
<ul>
<li class="chapter" data-level="15.1" data-path="intrinsic-rewards.html"><a href="intrinsic-rewards.html#the-sparse-reward-problem-and-its-implications"><i class="fa fa-check"></i><b>15.1</b> The Sparse Reward Problem and Its Implications</a></li>
<li class="chapter" data-level="15.2" data-path="intrinsic-rewards.html"><a href="intrinsic-rewards.html#mathematical-foundations-of-intrinsic-motivation"><i class="fa fa-check"></i><b>15.2</b> Mathematical Foundations of Intrinsic Motivation</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="intrinsic-rewards.html"><a href="intrinsic-rewards.html#curiosity-driven-learning"><i class="fa fa-check"></i><b>15.2.1</b> Curiosity-Driven Learning</a></li>
<li class="chapter" data-level="15.2.2" data-path="intrinsic-rewards.html"><a href="intrinsic-rewards.html#count-based-exploration"><i class="fa fa-check"></i><b>15.2.2</b> Count-Based Exploration</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="intrinsic-rewards.html"><a href="intrinsic-rewards.html#practical-implementation-curiosity-driven-grid-world-navigation"><i class="fa fa-check"></i><b>15.3</b> Practical Implementation: Curiosity-Driven Grid World Navigation</a></li>
<li class="chapter" data-level="15.4" data-path="intrinsic-rewards.html"><a href="intrinsic-rewards.html#advanced-intrinsic-motivation-mechanisms"><i class="fa fa-check"></i><b>15.4</b> Advanced Intrinsic Motivation Mechanisms</a></li>
<li class="chapter" data-level="15.5" data-path="intrinsic-rewards.html"><a href="intrinsic-rewards.html#implementation-considerations-and-practical-guidelines"><i class="fa fa-check"></i><b>15.5</b> Implementation Considerations and Practical Guidelines</a></li>
<li class="chapter" data-level="15.6" data-path="intrinsic-rewards.html"><a href="intrinsic-rewards.html#theoretical-analysis-and-convergence-properties"><i class="fa fa-check"></i><b>15.6</b> Theoretical Analysis and Convergence Properties</a></li>
<li class="chapter" data-level="15.7" data-path="intrinsic-rewards.html"><a href="intrinsic-rewards.html#applications-and-empirical-results"><i class="fa fa-check"></i><b>15.7</b> Applications and Empirical Results</a></li>
<li class="chapter" data-level="15.8" data-path="intrinsic-rewards.html"><a href="intrinsic-rewards.html#limitations-and-future-directions"><i class="fa fa-check"></i><b>15.8</b> Limitations and Future Directions</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html"><a href="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html"><i class="fa fa-check"></i><b>16</b> Policy Gradients: Direct Optimization of Action Selection in Reinforcement Learning</a>
<ul>
<li class="chapter" data-level="16.1" data-path="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html"><a href="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html#introduction-9"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html"><a href="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html#theoretical-framework-2"><i class="fa fa-check"></i><b>16.2</b> Theoretical Framework</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html"><a href="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html#the-policy-gradient-theorem-1"><i class="fa fa-check"></i><b>16.2.1</b> The Policy Gradient Theorem</a></li>
<li class="chapter" data-level="16.2.2" data-path="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html"><a href="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html#reinforce-algorithm"><i class="fa fa-check"></i><b>16.2.2</b> REINFORCE Algorithm</a></li>
<li class="chapter" data-level="16.2.3" data-path="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html"><a href="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html#baseline-subtraction-and-variance-reduction"><i class="fa fa-check"></i><b>16.2.3</b> Baseline Subtraction and Variance Reduction</a></li>
<li class="chapter" data-level="16.2.4" data-path="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html"><a href="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html#softmax-policy-parameterization"><i class="fa fa-check"></i><b>16.2.4</b> Softmax Policy Parameterization</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html"><a href="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html#implementation-in-r-2"><i class="fa fa-check"></i><b>16.3</b> Implementation in R</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html"><a href="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html#environment-and-feature-representation"><i class="fa fa-check"></i><b>16.3.1</b> Environment and Feature Representation</a></li>
<li class="chapter" data-level="16.3.2" data-path="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html"><a href="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html#softmax-policy-implementation"><i class="fa fa-check"></i><b>16.3.2</b> Softmax Policy Implementation</a></li>
<li class="chapter" data-level="16.3.3" data-path="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html"><a href="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html#reinforce-implementation"><i class="fa fa-check"></i><b>16.3.3</b> REINFORCE Implementation</a></li>
<li class="chapter" data-level="16.3.4" data-path="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html"><a href="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html#actor-critic-implementation"><i class="fa fa-check"></i><b>16.3.4</b> Actor-Critic Implementation</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html"><a href="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html#experimental-analysis-2"><i class="fa fa-check"></i><b>16.4</b> Experimental Analysis</a>
<ul>
<li class="chapter" data-level="16.4.1" data-path="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html"><a href="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html#comparison-of-policy-gradient-variants"><i class="fa fa-check"></i><b>16.4.1</b> Comparison of Policy Gradient Variants</a></li>
<li class="chapter" data-level="16.4.2" data-path="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html"><a href="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html#learning-rate-sensitivity-analysis"><i class="fa fa-check"></i><b>16.4.2</b> Learning Rate Sensitivity Analysis</a></li>
<li class="chapter" data-level="16.4.3" data-path="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html"><a href="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html#variance-analysis-of-gradient-estimates"><i class="fa fa-check"></i><b>16.4.3</b> Variance Analysis of Gradient Estimates</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html"><a href="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html#discussion-and-implementation-considerations-1"><i class="fa fa-check"></i><b>16.5</b> Discussion and Implementation Considerations</a></li>
<li class="chapter" data-level="16.6" data-path="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html"><a href="policy-gradients-direct-optimization-of-action-selection-in-reinforcement-learning.html#conclusion-9"><i class="fa fa-check"></i><b>16.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="actor-critic-methods-bridging-policy-and-value-learning-in-reinforcement-learning.html"><a href="actor-critic-methods-bridging-policy-and-value-learning-in-reinforcement-learning.html"><i class="fa fa-check"></i><b>17</b> Actor-Critic Methods: Bridging Policy and Value Learning in Reinforcement Learning</a>
<ul>
<li class="chapter" data-level="17.1" data-path="actor-critic-methods-bridging-policy-and-value-learning-in-reinforcement-learning.html"><a href="actor-critic-methods-bridging-policy-and-value-learning-in-reinforcement-learning.html#theoretical-framework-3"><i class="fa fa-check"></i><b>17.1</b> Theoretical Framework</a></li>
<li class="chapter" data-level="17.2" data-path="actor-critic-methods-bridging-policy-and-value-learning-in-reinforcement-learning.html"><a href="actor-critic-methods-bridging-policy-and-value-learning-in-reinforcement-learning.html#implementation-and-comparative-analysis"><i class="fa fa-check"></i><b>17.2</b> Implementation and Comparative Analysis</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="actor-critic-methods-bridging-policy-and-value-learning-in-reinforcement-learning.html"><a href="actor-critic-methods-bridging-policy-and-value-learning-in-reinforcement-learning.html#variance-analysis-and-learning-dynamics"><i class="fa fa-check"></i><b>17.2.1</b> Variance Analysis and Learning Dynamics</a></li>
<li class="chapter" data-level="17.2.2" data-path="actor-critic-methods-bridging-policy-and-value-learning-in-reinforcement-learning.html"><a href="actor-critic-methods-bridging-policy-and-value-learning-in-reinforcement-learning.html#algorithmic-variants-and-extensions"><i class="fa fa-check"></i><b>17.2.2</b> Algorithmic Variants and Extensions</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="actor-critic-methods-bridging-policy-and-value-learning-in-reinforcement-learning.html"><a href="actor-critic-methods-bridging-policy-and-value-learning-in-reinforcement-learning.html#computational-and-convergence-considerations"><i class="fa fa-check"></i><b>17.3</b> Computational and Convergence Considerations</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="actor-critic-methods-bridging-policy-and-value-learning-in-reinforcement-learning.html"><a href="actor-critic-methods-bridging-policy-and-value-learning-in-reinforcement-learning.html#comparative-performance-analysis"><i class="fa fa-check"></i><b>17.3.1</b> Comparative Performance Analysis</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="actor-critic-methods-bridging-policy-and-value-learning-in-reinforcement-learning.html"><a href="actor-critic-methods-bridging-policy-and-value-learning-in-reinforcement-learning.html#conclusion-10"><i class="fa fa-check"></i><b>17.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>18</b> Appendix</a>
<ul>
<li class="chapter" data-level="18.1" data-path="appendix.html"><a href="appendix.html#comprehensive-reinforcement-learning-concepts-guide"><i class="fa fa-check"></i><b>18.1</b> Comprehensive Reinforcement Learning Concepts Guide</a></li>
<li class="chapter" data-level="18.2" data-path="appendix.html"><a href="appendix.html#learning-mechanisms"><i class="fa fa-check"></i><b>18.2</b> Learning Mechanisms</a></li>
<li class="chapter" data-level="18.3" data-path="appendix.html"><a href="appendix.html#environment-properties"><i class="fa fa-check"></i><b>18.3</b> Environment Properties</a></li>
<li class="chapter" data-level="18.4" data-path="appendix.html"><a href="appendix.html#learning-paradigms"><i class="fa fa-check"></i><b>18.4</b> Learning Paradigms</a></li>
<li class="chapter" data-level="18.5" data-path="appendix.html"><a href="appendix.html#exploration-strategies"><i class="fa fa-check"></i><b>18.5</b> Exploration Strategies</a></li>
<li class="chapter" data-level="18.6" data-path="appendix.html"><a href="appendix.html#key-algorithms-methods"><i class="fa fa-check"></i><b>18.6</b> Key Algorithms &amp; Methods</a></li>
<li class="chapter" data-level="18.7" data-path="appendix.html"><a href="appendix.html#advanced-concepts"><i class="fa fa-check"></i><b>18.7</b> Advanced Concepts</a></li>
<li class="chapter" data-level="18.8" data-path="appendix.html"><a href="appendix.html#fundamental-equations"><i class="fa fa-check"></i><b>18.8</b> Fundamental Equations</a>
<ul>
<li class="chapter" data-level="18.8.1" data-path="appendix.html"><a href="appendix.html#bellman-equations"><i class="fa fa-check"></i><b>18.8.1</b> <strong>Bellman Equations</strong></a></li>
<li class="chapter" data-level="18.8.2" data-path="appendix.html"><a href="appendix.html#policy-gradient-theorem"><i class="fa fa-check"></i><b>18.8.2</b> <strong>Policy Gradient Theorem</strong></a></li>
<li class="chapter" data-level="18.8.3" data-path="appendix.html"><a href="appendix.html#temporal-difference-error"><i class="fa fa-check"></i><b>18.8.3</b> <strong>Temporal Difference Error</strong></a></li>
</ul></li>
<li class="chapter" data-level="18.9" data-path="appendix.html"><a href="appendix.html#common-challenges-solutions"><i class="fa fa-check"></i><b>18.9</b> Common Challenges &amp; Solutions</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Reinforcement Learning in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="function-approximation-and-feature-engineering" class="section level1 hasAnchor" number="11">
<h1><span class="header-section-number">Chapter 11</span> Function Approximation And Feature Engineering<a href="function-approximation-and-feature-engineering.html#function-approximation-and-feature-engineering" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Reinforcement Learning (RL) has made remarkable progress, largely by moving from <strong>tabular methods</strong>, which store values for every state, to <strong>deep learning</strong> approaches that can handle vast, continuous environments. This leap, however, is built upon a critical intermediate step: <strong>classical function approximation</strong>. Understanding linear function approximation, basis functions, and feature engineering is essential for grasping why deep RL works, diagnosing its failures, and designing effective agent representations.</p>
<p>Tabular RL is impractical for large or continuous state spaces due to the <strong>curse of dimensionality</strong>. Function approximation overcomes this by learning a parameterized function that generalizes knowledge across similar states. This generalization is both a strength and a challenge. It allows agents to learn in complex worlds but introduces a fundamental tradeoff between <strong>discrimination</strong> (distinguishing important states) and <strong>generalization</strong> (sharing knowledge) that shapes all modern RL algorithms.</p>
<p>This appendix bridges the gap between tabular methods and deep RL. We begin with feature engineering, then cover the mathematical principles of linear function approximation, and finally explore classical basis functions like coarse coding, tile coding, and radial basis functions (RBFs).</p>
<div id="feature-engineering-and-state-representation" class="section level2 hasAnchor" number="11.1">
<h2><span class="header-section-number">11.1</span> Feature Engineering and State Representation<a href="function-approximation-and-feature-engineering.html#feature-engineering-and-state-representation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The success of any RL algorithm hinges on the quality of its state representation. Raw environmental observations are rarely optimal for learning. Effective <strong>feature engineering</strong> transforms high-dimensional, noisy data into a compact, informative format that accelerates learning and improves generalization.</p>
<div id="the-discrimination-vs.-generalization-tradeoff" class="section level3 hasAnchor" number="11.1.1">
<h3><span class="header-section-number">11.1.1</span> The Discrimination vs. Generalization Tradeoff<a href="function-approximation-and-feature-engineering.html#the-discrimination-vs.-generalization-tradeoff" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>At the core of feature design is a fundamental tension:</p>
<ul>
<li><strong>Discrimination</strong> is the ability to distinguish between states that require different actions or have different values. For example, a robot navigating near a cliff must have features that are highly sensitive to small changes in its position.</li>
<li><strong>Generalization</strong> is the ability to treat similar states similarly, allowing experiences in one state to inform decisions in others. In the same navigation task, large open areas should be represented similarly so the agent doesn’t have to re-learn how to move in each one.</li>
</ul>
<p>Mathematically, we approximate a value function <span class="math inline">\(V^\*(s)\)</span> with a parameterized function <span class="math inline">\(V\_{\\boldsymbol{\\theta}}(s)\)</span>. Using a linear model, this is expressed as:</p>
<p><span class="math display">\[V_{\boldsymbol{\theta}}(s) = \boldsymbol{\phi}(s)^T \boldsymbol{\theta} = \sum_{i=1}^d \phi_i(s) \theta_i\]</span></p>
<p>Here, <span class="math inline">\(\\boldsymbol{\\phi}(s)\)</span> is the feature vector for state <span class="math inline">\(s\)</span>, and <span class="math inline">\(\\boldsymbol{\\theta}\)</span> is the weight vector we learn. The quality of the approximation depends on how well the features <span class="math inline">\(\\boldsymbol{\\phi}(s)\)</span> can represent the true value function <span class="math inline">\(V^*(s)\)</span>. The unavoidable error in the best possible linear approximation is given by <span class="math inline">\(|V^* - \\Pi V^\*|^2\)</span>, where <span class="math inline">\(\\Pi\)</span> is the projection operator onto the space spanned by the features. A good feature set minimizes this error.</p>
</div>
<div id="principles-of-feature-extraction" class="section level3 hasAnchor" number="11.1.2">
<h3><span class="header-section-number">11.1.2</span> Principles of Feature Extraction<a href="function-approximation-and-feature-engineering.html#principles-of-feature-extraction" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Effective feature design in RL often involves:</p>
<ul>
<li><strong>Encoding Temporal Dependencies</strong>: Features should capture dynamics, such as position and velocity in a physics problem or recent price trends in a trading algorithm.</li>
<li><strong>Focusing on Action-Relevant Information</strong>: Features should highlight aspects of the state that are critical for making a decision. The shape of a chess position is more important than the specific pieces if the underlying tactical pattern is the same.</li>
<li><strong>Capturing Hierarchical Structure</strong>: Good features can represent abstract concepts, like “in the kitchen” for a home robot or “opening phase” in a board game, which allows for hierarchical planning and learning.</li>
</ul>
</div>
</div>
<div id="mathematical-foundations-of-linear-function-approximation" class="section level2 hasAnchor" number="11.2">
<h2><span class="header-section-number">11.2</span> Mathematical Foundations of Linear Function Approximation<a href="function-approximation-and-feature-engineering.html#mathematical-foundations-of-linear-function-approximation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Linear function approximation is the cornerstone of parametric value function methods. Its simplicity provides theoretical guarantees and computational efficiency, making it an essential starting point.</p>
<div id="linear-value-functions" class="section level3 hasAnchor" number="11.2.1">
<h3><span class="header-section-number">11.2.1</span> Linear Value Functions<a href="function-approximation-and-feature-engineering.html#linear-value-functions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We represent the state-value function <span class="math inline">\(V(s)\)</span> or action-value function <span class="math inline">\(Q(s, a)\)</span> as a linear combination of features:
<span class="math display">\[V_{\boldsymbol{\theta}}(s) = \boldsymbol{\phi}(s)^T \boldsymbol{\theta}\]</span>
<span class="math display">\[Q_{\boldsymbol{\theta}}(s, a) = \boldsymbol{\phi}(s, a)^T \boldsymbol{\theta}\]</span>
A key advantage is that the gradient of the value function with respect to the parameters is simply the feature vector itself:
<span class="math display">\[\nabla_{\boldsymbol{\theta}} V_{\boldsymbol{\theta}}(s) = \boldsymbol{\phi}(s)\]</span>
This property makes learning algorithms based on gradient descent straightforward and computationally cheap.</p>
</div>
<div id="temporal-difference-td-learning-with-function-approximation" class="section level3 hasAnchor" number="11.2.2">
<h3><span class="header-section-number">11.2.2</span> Temporal Difference (TD) Learning with Function Approximation<a href="function-approximation-and-feature-engineering.html#temporal-difference-td-learning-with-function-approximation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>With linear function approximation, the <strong>TD(0)</strong> update rule for learning <span class="math inline">\(V\_{\\boldsymbol{\\theta}}(s)\)</span> becomes:
<span class="math display">\[\boldsymbol{\theta}_{t+1} \leftarrow \boldsymbol{\theta}_t + \alpha [R_{t+1} + \gamma V_{\boldsymbol{\theta}}(S_{t+1}) - V_{\boldsymbol{\theta}}(S_t)] \boldsymbol{\phi}(S_t)\]</span>
This update adjusts the weights <span class="math inline">\(\\boldsymbol{\\theta}\)</span> to reduce the TD error for the observed transition. Since the value of any state depends on the shared weights <span class="math inline">\(\\boldsymbol{\\theta}\)</span>, this single update influences the value estimates across the entire state space.</p>
<p>Similarly, the update for <strong>Q-learning</strong> is:
<span class="math display">\[\boldsymbol{\theta}_{t+1} \leftarrow \boldsymbol{\theta}_t + \alpha [R_{t+1} + \gamma \max_{a&#39;} Q_{\boldsymbol{\theta}}(S_{t+1}, a&#39;) - Q_{\boldsymbol{\theta}}(S_t, A_t)] \boldsymbol{\phi}(S_t, A_t)\]</span></p>
</div>
<div id="convergence-and-the-deadly-triad" class="section level3 hasAnchor" number="11.2.3">
<h3><span class="header-section-number">11.2.3</span> Convergence and the “Deadly Triad”<a href="function-approximation-and-feature-engineering.html#convergence-and-the-deadly-triad" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>While on-policy TD learning with linear function approximation is guaranteed to converge, stability is not assured under all conditions. The combination of <strong>off-policy learning</strong>, <strong>function approximation</strong>, and <strong>bootstrapping</strong> (updating estimates from other estimates) is known as the <strong>“deadly triad”</strong> and can lead to divergence, where the value estimates grow uncontrollably. This instability is a fundamental challenge that motivated much of the research leading to modern deep RL algorithms like DQN, which employ techniques like experience replay and target networks to mitigate it.</p>
</div>
</div>
<div id="classical-basis-function-methods" class="section level2 hasAnchor" number="11.3">
<h2><span class="header-section-number">11.3</span> Classical Basis Function Methods<a href="function-approximation-and-feature-engineering.html#classical-basis-function-methods" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Basis functions are systematic methods for constructing features. They provide a bridge from simple linear models to the powerful, automatically-learned features of neural networks.</p>
<div id="coarse-coding" class="section level3 hasAnchor" number="11.3.1">
<h3><span class="header-section-number">11.3.1</span> Coarse Coding<a href="function-approximation-and-feature-engineering.html#coarse-coding" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Coarse coding</strong> uses overlapping binary features, where each feature corresponds to a “receptive field” or region in the state space. A feature is active (value 1) if the state falls within its region and inactive (0) otherwise. The overlap between regions enables generalization: nearby states activate a similar set of features, so they receive similar value estimates.</p>
<p>The degree of overlap controls the smoothness of the learned function. More overlap leads to broader generalization.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="function-approximation-and-feature-engineering.html#cb36-1" tabindex="-1"></a><span class="co"># Load necessary libraries for all visualizations</span></span>
<span id="cb36-2"><a href="function-approximation-and-feature-engineering.html#cb36-2" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb36-3"><a href="function-approximation-and-feature-engineering.html#cb36-3" tabindex="-1"></a><span class="fu">library</span>(ggforce) <span class="co"># For drawing circles</span></span>
<span id="cb36-4"><a href="function-approximation-and-feature-engineering.html#cb36-4" tabindex="-1"></a></span>
<span id="cb36-5"><a href="function-approximation-and-feature-engineering.html#cb36-5" tabindex="-1"></a><span class="co"># --- Coarse Coding Implementation ---</span></span>
<span id="cb36-6"><a href="function-approximation-and-feature-engineering.html#cb36-6" tabindex="-1"></a>create_coarse_coder <span class="ot">&lt;-</span> <span class="cf">function</span>(state_dims, num_features, <span class="at">overlap_factor =</span> <span class="dv">2</span>) {</span>
<span id="cb36-7"><a href="function-approximation-and-feature-engineering.html#cb36-7" tabindex="-1"></a>  <span class="co"># Generate random centers for the receptive fields</span></span>
<span id="cb36-8"><a href="function-approximation-and-feature-engineering.html#cb36-8" tabindex="-1"></a>  centers <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb36-9"><a href="function-approximation-and-feature-engineering.html#cb36-9" tabindex="-1"></a>    <span class="at">x =</span> <span class="fu">runif</span>(num_features, <span class="dv">0</span>, state_dims[<span class="dv">1</span>]),</span>
<span id="cb36-10"><a href="function-approximation-and-feature-engineering.html#cb36-10" tabindex="-1"></a>    <span class="at">y =</span> <span class="fu">runif</span>(num_features, <span class="dv">0</span>, state_dims[<span class="dv">2</span>])</span>
<span id="cb36-11"><a href="function-approximation-and-feature-engineering.html#cb36-11" tabindex="-1"></a>  )</span>
<span id="cb36-12"><a href="function-approximation-and-feature-engineering.html#cb36-12" tabindex="-1"></a>  </span>
<span id="cb36-13"><a href="function-approximation-and-feature-engineering.html#cb36-13" tabindex="-1"></a>  <span class="co"># Calculate radius based on average spacing to ensure overlap</span></span>
<span id="cb36-14"><a href="function-approximation-and-feature-engineering.html#cb36-14" tabindex="-1"></a>  avg_spacing <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">prod</span>(state_dims) <span class="sc">/</span> num_features)</span>
<span id="cb36-15"><a href="function-approximation-and-feature-engineering.html#cb36-15" tabindex="-1"></a>  radius <span class="ot">&lt;-</span> overlap_factor <span class="sc">*</span> avg_spacing <span class="sc">/</span> <span class="dv">2</span></span>
<span id="cb36-16"><a href="function-approximation-and-feature-engineering.html#cb36-16" tabindex="-1"></a>  </span>
<span id="cb36-17"><a href="function-approximation-and-feature-engineering.html#cb36-17" tabindex="-1"></a>  <span class="co"># Function to compute the binary feature vector for a given state</span></span>
<span id="cb36-18"><a href="function-approximation-and-feature-engineering.html#cb36-18" tabindex="-1"></a>  compute_features <span class="ot">&lt;-</span> <span class="cf">function</span>(state) {</span>
<span id="cb36-19"><a href="function-approximation-and-feature-engineering.html#cb36-19" tabindex="-1"></a>    state_vec <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(state)</span>
<span id="cb36-20"><a href="function-approximation-and-feature-engineering.html#cb36-20" tabindex="-1"></a>    distances <span class="ot">&lt;-</span> <span class="fu">sqrt</span>((centers<span class="sc">$</span>x <span class="sc">-</span> state_vec[<span class="dv">1</span>])<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> (centers<span class="sc">$</span>y <span class="sc">-</span> state_vec[<span class="dv">2</span>])<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb36-21"><a href="function-approximation-and-feature-engineering.html#cb36-21" tabindex="-1"></a>    features <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(distances <span class="sc">&lt;=</span> radius)</span>
<span id="cb36-22"><a href="function-approximation-and-feature-engineering.html#cb36-22" tabindex="-1"></a>    <span class="fu">return</span>(features)</span>
<span id="cb36-23"><a href="function-approximation-and-feature-engineering.html#cb36-23" tabindex="-1"></a>  }</span>
<span id="cb36-24"><a href="function-approximation-and-feature-engineering.html#cb36-24" tabindex="-1"></a>  </span>
<span id="cb36-25"><a href="function-approximation-and-feature-engineering.html#cb36-25" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(</span>
<span id="cb36-26"><a href="function-approximation-and-feature-engineering.html#cb36-26" tabindex="-1"></a>    <span class="at">compute_features =</span> compute_features,</span>
<span id="cb36-27"><a href="function-approximation-and-feature-engineering.html#cb36-27" tabindex="-1"></a>    <span class="at">centers =</span> centers,</span>
<span id="cb36-28"><a href="function-approximation-and-feature-engineering.html#cb36-28" tabindex="-1"></a>    <span class="at">radius =</span> radius,</span>
<span id="cb36-29"><a href="function-approximation-and-feature-engineering.html#cb36-29" tabindex="-1"></a>    <span class="at">state_dims =</span> state_dims</span>
<span id="cb36-30"><a href="function-approximation-and-feature-engineering.html#cb36-30" tabindex="-1"></a>  ))</span>
<span id="cb36-31"><a href="function-approximation-and-feature-engineering.html#cb36-31" tabindex="-1"></a>}</span>
<span id="cb36-32"><a href="function-approximation-and-feature-engineering.html#cb36-32" tabindex="-1"></a></span>
<span id="cb36-33"><a href="function-approximation-and-feature-engineering.html#cb36-33" tabindex="-1"></a><span class="co"># --- Visualization Function for Coarse Coding ---</span></span>
<span id="cb36-34"><a href="function-approximation-and-feature-engineering.html#cb36-34" tabindex="-1"></a>visualize_coarse_coding <span class="ot">&lt;-</span> <span class="cf">function</span>(coarse_coder, <span class="at">state =</span> <span class="cn">NULL</span>) {</span>
<span id="cb36-35"><a href="function-approximation-and-feature-engineering.html#cb36-35" tabindex="-1"></a>  active_features <span class="ot">&lt;-</span> <span class="cf">if</span> (<span class="sc">!</span><span class="fu">is.null</span>(state)) coarse_coder<span class="sc">$</span><span class="fu">compute_features</span>(state) <span class="cf">else</span> <span class="cn">NULL</span></span>
<span id="cb36-36"><a href="function-approximation-and-feature-engineering.html#cb36-36" tabindex="-1"></a>  active_indices <span class="ot">&lt;-</span> <span class="cf">if</span> (<span class="sc">!</span><span class="fu">is.null</span>(active_features)) <span class="fu">which</span>(active_features <span class="sc">==</span> <span class="dv">1</span>) <span class="cf">else</span> <span class="fu">integer</span>(<span class="dv">0</span>)</span>
<span id="cb36-37"><a href="function-approximation-and-feature-engineering.html#cb36-37" tabindex="-1"></a>  </span>
<span id="cb36-38"><a href="function-approximation-and-feature-engineering.html#cb36-38" tabindex="-1"></a>  p <span class="ot">&lt;-</span> <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb36-39"><a href="function-approximation-and-feature-engineering.html#cb36-39" tabindex="-1"></a>    <span class="co"># Draw all receptive fields (inactive)</span></span>
<span id="cb36-40"><a href="function-approximation-and-feature-engineering.html#cb36-40" tabindex="-1"></a>    <span class="fu">geom_circle</span>(</span>
<span id="cb36-41"><a href="function-approximation-and-feature-engineering.html#cb36-41" tabindex="-1"></a>      <span class="at">data =</span> coarse_coder<span class="sc">$</span>centers,</span>
<span id="cb36-42"><a href="function-approximation-and-feature-engineering.html#cb36-42" tabindex="-1"></a>      <span class="fu">aes</span>(<span class="at">x0 =</span> x, <span class="at">y0 =</span> y, <span class="at">r =</span> coarse_coder<span class="sc">$</span>radius),</span>
<span id="cb36-43"><a href="function-approximation-and-feature-engineering.html#cb36-43" tabindex="-1"></a>      <span class="at">color =</span> <span class="st">&quot;grey70&quot;</span>, <span class="at">fill =</span> <span class="cn">NA</span>, <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span></span>
<span id="cb36-44"><a href="function-approximation-and-feature-engineering.html#cb36-44" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb36-45"><a href="function-approximation-and-feature-engineering.html#cb36-45" tabindex="-1"></a>    <span class="co"># Highlight active receptive fields</span></span>
<span id="cb36-46"><a href="function-approximation-and-feature-engineering.html#cb36-46" tabindex="-1"></a>    <span class="fu">geom_circle</span>(</span>
<span id="cb36-47"><a href="function-approximation-and-feature-engineering.html#cb36-47" tabindex="-1"></a>      <span class="at">data =</span> coarse_coder<span class="sc">$</span>centers[active_indices, ],</span>
<span id="cb36-48"><a href="function-approximation-and-feature-engineering.html#cb36-48" tabindex="-1"></a>      <span class="fu">aes</span>(<span class="at">x0 =</span> x, <span class="at">y0 =</span> y, <span class="at">r =</span> coarse_coder<span class="sc">$</span>radius),</span>
<span id="cb36-49"><a href="function-approximation-and-feature-engineering.html#cb36-49" tabindex="-1"></a>      <span class="at">color =</span> <span class="st">&quot;#e41a1c&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;#e41a1c&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.2</span>, <span class="at">size =</span> <span class="dv">1</span></span>
<span id="cb36-50"><a href="function-approximation-and-feature-engineering.html#cb36-50" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb36-51"><a href="function-approximation-and-feature-engineering.html#cb36-51" tabindex="-1"></a>    <span class="co"># Add center points</span></span>
<span id="cb36-52"><a href="function-approximation-and-feature-engineering.html#cb36-52" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">data =</span> coarse_coder<span class="sc">$</span>centers, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y), <span class="at">color =</span> <span class="st">&quot;grey50&quot;</span>, <span class="at">size =</span> <span class="dv">1</span>)</span>
<span id="cb36-53"><a href="function-approximation-and-feature-engineering.html#cb36-53" tabindex="-1"></a>  </span>
<span id="cb36-54"><a href="function-approximation-and-feature-engineering.html#cb36-54" tabindex="-1"></a>  <span class="co"># Add the query state point</span></span>
<span id="cb36-55"><a href="function-approximation-and-feature-engineering.html#cb36-55" tabindex="-1"></a>  <span class="cf">if</span> (<span class="sc">!</span><span class="fu">is.null</span>(state)) {</span>
<span id="cb36-56"><a href="function-approximation-and-feature-engineering.html#cb36-56" tabindex="-1"></a>    p <span class="ot">&lt;-</span> p <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x =</span> state[<span class="dv">1</span>], <span class="at">y =</span> state[<span class="dv">2</span>]), <span class="at">color =</span> <span class="st">&quot;#377eb8&quot;</span>, <span class="at">size =</span> <span class="dv">5</span>, <span class="at">shape =</span> <span class="dv">17</span>)</span>
<span id="cb36-57"><a href="function-approximation-and-feature-engineering.html#cb36-57" tabindex="-1"></a>  }</span>
<span id="cb36-58"><a href="function-approximation-and-feature-engineering.html#cb36-58" tabindex="-1"></a>  </span>
<span id="cb36-59"><a href="function-approximation-and-feature-engineering.html#cb36-59" tabindex="-1"></a>  p <span class="sc">+</span></span>
<span id="cb36-60"><a href="function-approximation-and-feature-engineering.html#cb36-60" tabindex="-1"></a>    <span class="fu">coord_fixed</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, coarse_coder<span class="sc">$</span>state_dims[<span class="dv">1</span>]), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, coarse_coder<span class="sc">$</span>state_dims[<span class="dv">2</span>])) <span class="sc">+</span></span>
<span id="cb36-61"><a href="function-approximation-and-feature-engineering.html#cb36-61" tabindex="-1"></a>    <span class="fu">labs</span>(</span>
<span id="cb36-62"><a href="function-approximation-and-feature-engineering.html#cb36-62" tabindex="-1"></a>      <span class="at">title =</span> <span class="st">&quot;Coarse Coding Receptive Fields&quot;</span>,</span>
<span id="cb36-63"><a href="function-approximation-and-feature-engineering.html#cb36-63" tabindex="-1"></a>      <span class="at">subtitle =</span> <span class="fu">paste</span>(<span class="fu">length</span>(active_indices), <span class="st">&quot;of&quot;</span>, <span class="fu">nrow</span>(coarse_coder<span class="sc">$</span>centers), <span class="st">&quot;features active&quot;</span>),</span>
<span id="cb36-64"><a href="function-approximation-and-feature-engineering.html#cb36-64" tabindex="-1"></a>      <span class="at">x =</span> <span class="st">&quot;State Dimension 1&quot;</span>,</span>
<span id="cb36-65"><a href="function-approximation-and-feature-engineering.html#cb36-65" tabindex="-1"></a>      <span class="at">y =</span> <span class="st">&quot;State Dimension 2&quot;</span></span>
<span id="cb36-66"><a href="function-approximation-and-feature-engineering.html#cb36-66" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb36-67"><a href="function-approximation-and-feature-engineering.html#cb36-67" tabindex="-1"></a>    <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">14</span>)</span>
<span id="cb36-68"><a href="function-approximation-and-feature-engineering.html#cb36-68" tabindex="-1"></a>}</span>
<span id="cb36-69"><a href="function-approximation-and-feature-engineering.html#cb36-69" tabindex="-1"></a></span>
<span id="cb36-70"><a href="function-approximation-and-feature-engineering.html#cb36-70" tabindex="-1"></a><span class="co"># Example Usage</span></span>
<span id="cb36-71"><a href="function-approximation-and-feature-engineering.html#cb36-71" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb36-72"><a href="function-approximation-and-feature-engineering.html#cb36-72" tabindex="-1"></a>coarse_coder_2d <span class="ot">&lt;-</span> <span class="fu">create_coarse_coder</span>(<span class="at">state_dims =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">10</span>), <span class="at">num_features =</span> <span class="dv">50</span>, <span class="at">overlap_factor =</span> <span class="fl">1.5</span>)</span>
<span id="cb36-73"><a href="function-approximation-and-feature-engineering.html#cb36-73" tabindex="-1"></a><span class="fu">visualize_coarse_coding</span>(coarse_coder_2d, <span class="at">state =</span> <span class="fu">c</span>(<span class="fl">3.2</span>, <span class="fl">7.8</span>))</span></code></pre></div>
</div>
<div id="tile-coding" class="section level3 hasAnchor" number="11.3.2">
<h3><span class="header-section-number">11.3.2</span> Tile Coding<a href="function-approximation-and-feature-engineering.html#tile-coding" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Tile coding</strong>, also known as CMAC (Cerebellar Model Articulation Controller), improves upon coarse coding by providing more structured and uniform coverage. It partitions the state space using multiple overlapping grids, called <strong>tilings</strong>. Each tiling is offset from the others. For any given state, exactly one tile in each tiling will be active. This ensures a constant number of active features, which is computationally efficient.</p>
<p>The offsets provide fine-grained discrimination, while the tile size controls generalization. Unlike coarse coding with circular fields, tile coding’s rectangular tiles create <strong>asymmetric generalization</strong> that aligns with the coordinate axes, which is often desirable in control problems where dimensions represent different physical properties (e.g., position and velocity).</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="function-approximation-and-feature-engineering.html#cb37-1" tabindex="-1"></a><span class="co"># --- Tile Coding Implementation ---</span></span>
<span id="cb37-2"><a href="function-approximation-and-feature-engineering.html#cb37-2" tabindex="-1"></a>create_tile_coder <span class="ot">&lt;-</span> <span class="cf">function</span>(state_low, state_high, num_tilings, tiles_per_dim) {</span>
<span id="cb37-3"><a href="function-approximation-and-feature-engineering.html#cb37-3" tabindex="-1"></a>  state_dims <span class="ot">&lt;-</span> <span class="fu">length</span>(state_low)</span>
<span id="cb37-4"><a href="function-approximation-and-feature-engineering.html#cb37-4" tabindex="-1"></a>  state_range <span class="ot">&lt;-</span> state_high <span class="sc">-</span> state_low</span>
<span id="cb37-5"><a href="function-approximation-and-feature-engineering.html#cb37-5" tabindex="-1"></a>  tile_widths <span class="ot">&lt;-</span> state_range <span class="sc">/</span> tiles_per_dim</span>
<span id="cb37-6"><a href="function-approximation-and-feature-engineering.html#cb37-6" tabindex="-1"></a>  </span>
<span id="cb37-7"><a href="function-approximation-and-feature-engineering.html#cb37-7" tabindex="-1"></a>  <span class="co"># Generate offsets for each tiling</span></span>
<span id="cb37-8"><a href="function-approximation-and-feature-engineering.html#cb37-8" tabindex="-1"></a>  offsets <span class="ot">&lt;-</span> <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span>state_dims, <span class="cf">function</span>(i) {</span>
<span id="cb37-9"><a href="function-approximation-and-feature-engineering.html#cb37-9" tabindex="-1"></a>    (<span class="dv">1</span><span class="sc">:</span>num_tilings <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> tile_widths[i] <span class="sc">/</span> num_tilings</span>
<span id="cb37-10"><a href="function-approximation-and-feature-engineering.html#cb37-10" tabindex="-1"></a>  })</span>
<span id="cb37-11"><a href="function-approximation-and-feature-engineering.html#cb37-11" tabindex="-1"></a>  </span>
<span id="cb37-12"><a href="function-approximation-and-feature-engineering.html#cb37-12" tabindex="-1"></a>  <span class="co"># Function to get the indices of active tiles for a given state</span></span>
<span id="cb37-13"><a href="function-approximation-and-feature-engineering.html#cb37-13" tabindex="-1"></a>  get_active_tiles <span class="ot">&lt;-</span> <span class="cf">function</span>(state) {</span>
<span id="cb37-14"><a href="function-approximation-and-feature-engineering.html#cb37-14" tabindex="-1"></a>    active_tiles <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb37-15"><a href="function-approximation-and-feature-engineering.html#cb37-15" tabindex="-1"></a>    <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>num_tilings) {</span>
<span id="cb37-16"><a href="function-approximation-and-feature-engineering.html#cb37-16" tabindex="-1"></a>      tile_indices <span class="ot">&lt;-</span> <span class="fu">floor</span>((state <span class="sc">-</span> state_low <span class="sc">+</span> offsets[t, ]) <span class="sc">/</span> tile_widths)</span>
<span id="cb37-17"><a href="function-approximation-and-feature-engineering.html#cb37-17" tabindex="-1"></a>      active_tiles[[t]] <span class="ot">&lt;-</span> tile_indices</span>
<span id="cb37-18"><a href="function-approximation-and-feature-engineering.html#cb37-18" tabindex="-1"></a>    }</span>
<span id="cb37-19"><a href="function-approximation-and-feature-engineering.html#cb37-19" tabindex="-1"></a>    <span class="fu">return</span>(active_tiles)</span>
<span id="cb37-20"><a href="function-approximation-and-feature-engineering.html#cb37-20" tabindex="-1"></a>  }</span>
<span id="cb37-21"><a href="function-approximation-and-feature-engineering.html#cb37-21" tabindex="-1"></a>  </span>
<span id="cb37-22"><a href="function-approximation-and-feature-engineering.html#cb37-22" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(</span>
<span id="cb37-23"><a href="function-approximation-and-feature-engineering.html#cb37-23" tabindex="-1"></a>    <span class="at">get_active_tiles =</span> get_active_tiles,</span>
<span id="cb37-24"><a href="function-approximation-and-feature-engineering.html#cb37-24" tabindex="-1"></a>    <span class="at">state_low =</span> state_low,</span>
<span id="cb37-25"><a href="function-approximation-and-feature-engineering.html#cb37-25" tabindex="-1"></a>    <span class="at">state_high =</span> state_high,</span>
<span id="cb37-26"><a href="function-approximation-and-feature-engineering.html#cb37-26" tabindex="-1"></a>    <span class="at">num_tilings =</span> num_tilings,</span>
<span id="cb37-27"><a href="function-approximation-and-feature-engineering.html#cb37-27" tabindex="-1"></a>    <span class="at">tiles_per_dim =</span> tiles_per_dim,</span>
<span id="cb37-28"><a href="function-approximation-and-feature-engineering.html#cb37-28" tabindex="-1"></a>    <span class="at">tile_widths =</span> tile_widths,</span>
<span id="cb37-29"><a href="function-approximation-and-feature-engineering.html#cb37-29" tabindex="-1"></a>    <span class="at">offsets =</span> offsets</span>
<span id="cb37-30"><a href="function-approximation-and-feature-engineering.html#cb37-30" tabindex="-1"></a>  ))</span>
<span id="cb37-31"><a href="function-approximation-and-feature-engineering.html#cb37-31" tabindex="-1"></a>}</span>
<span id="cb37-32"><a href="function-approximation-and-feature-engineering.html#cb37-32" tabindex="-1"></a></span>
<span id="cb37-33"><a href="function-approximation-and-feature-engineering.html#cb37-33" tabindex="-1"></a><span class="co"># --- Visualization Function for Tile Coding ---</span></span>
<span id="cb37-34"><a href="function-approximation-and-feature-engineering.html#cb37-34" tabindex="-1"></a>visualize_tile_coding <span class="ot">&lt;-</span> <span class="cf">function</span>(tile_coder, <span class="at">state =</span> <span class="cn">NULL</span>) {</span>
<span id="cb37-35"><a href="function-approximation-and-feature-engineering.html#cb37-35" tabindex="-1"></a>  <span class="cf">if</span> (<span class="fu">length</span>(tile_coder<span class="sc">$</span>state_low) <span class="sc">!=</span> <span class="dv">2</span>) <span class="fu">stop</span>(<span class="st">&quot;Visualization is for 2D state spaces only.&quot;</span>)</span>
<span id="cb37-36"><a href="function-approximation-and-feature-engineering.html#cb37-36" tabindex="-1"></a>  </span>
<span id="cb37-37"><a href="function-approximation-and-feature-engineering.html#cb37-37" tabindex="-1"></a>  <span class="co"># Create a data frame of grid lines for each tiling</span></span>
<span id="cb37-38"><a href="function-approximation-and-feature-engineering.html#cb37-38" tabindex="-1"></a>  grids <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb37-39"><a href="function-approximation-and-feature-engineering.html#cb37-39" tabindex="-1"></a>  <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>tile_coder<span class="sc">$</span>num_tilings) {</span>
<span id="cb37-40"><a href="function-approximation-and-feature-engineering.html#cb37-40" tabindex="-1"></a>    <span class="co"># Vertical lines</span></span>
<span id="cb37-41"><a href="function-approximation-and-feature-engineering.html#cb37-41" tabindex="-1"></a>    x_lines <span class="ot">&lt;-</span> <span class="fu">seq</span>(</span>
<span id="cb37-42"><a href="function-approximation-and-feature-engineering.html#cb37-42" tabindex="-1"></a>      tile_coder<span class="sc">$</span>state_low[<span class="dv">1</span>] <span class="sc">-</span> tile_coder<span class="sc">$</span>offsets[t, <span class="dv">1</span>],</span>
<span id="cb37-43"><a href="function-approximation-and-feature-engineering.html#cb37-43" tabindex="-1"></a>      tile_coder<span class="sc">$</span>state_high[<span class="dv">1</span>],</span>
<span id="cb37-44"><a href="function-approximation-and-feature-engineering.html#cb37-44" tabindex="-1"></a>      <span class="at">by =</span> tile_coder<span class="sc">$</span>tile_widths[<span class="dv">1</span>]</span>
<span id="cb37-45"><a href="function-approximation-and-feature-engineering.html#cb37-45" tabindex="-1"></a>    )</span>
<span id="cb37-46"><a href="function-approximation-and-feature-engineering.html#cb37-46" tabindex="-1"></a>    <span class="co"># Horizontal lines</span></span>
<span id="cb37-47"><a href="function-approximation-and-feature-engineering.html#cb37-47" tabindex="-1"></a>    y_lines <span class="ot">&lt;-</span> <span class="fu">seq</span>(</span>
<span id="cb37-48"><a href="function-approximation-and-feature-engineering.html#cb37-48" tabindex="-1"></a>      tile_coder<span class="sc">$</span>state_low[<span class="dv">2</span>] <span class="sc">-</span> tile_coder<span class="sc">$</span>offsets[t, <span class="dv">2</span>],</span>
<span id="cb37-49"><a href="function-approximation-and-feature-engineering.html#cb37-49" tabindex="-1"></a>      tile_coder<span class="sc">$</span>state_high[<span class="dv">2</span>],</span>
<span id="cb37-50"><a href="function-approximation-and-feature-engineering.html#cb37-50" tabindex="-1"></a>      <span class="at">by =</span> tile_coder<span class="sc">$</span>tile_widths[<span class="dv">2</span>]</span>
<span id="cb37-51"><a href="function-approximation-and-feature-engineering.html#cb37-51" tabindex="-1"></a>    )</span>
<span id="cb37-52"><a href="function-approximation-and-feature-engineering.html#cb37-52" tabindex="-1"></a>    grids[[t]] <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">x =</span> x_lines, <span class="at">y =</span> y_lines)</span>
<span id="cb37-53"><a href="function-approximation-and-feature-engineering.html#cb37-53" tabindex="-1"></a>  }</span>
<span id="cb37-54"><a href="function-approximation-and-feature-engineering.html#cb37-54" tabindex="-1"></a>  </span>
<span id="cb37-55"><a href="function-approximation-and-feature-engineering.html#cb37-55" tabindex="-1"></a>  <span class="co"># Base plot</span></span>
<span id="cb37-56"><a href="function-approximation-and-feature-engineering.html#cb37-56" tabindex="-1"></a>  p <span class="ot">&lt;-</span> <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb37-57"><a href="function-approximation-and-feature-engineering.html#cb37-57" tabindex="-1"></a>    <span class="fu">coord_fixed</span>(</span>
<span id="cb37-58"><a href="function-approximation-and-feature-engineering.html#cb37-58" tabindex="-1"></a>      <span class="at">xlim =</span> tile_coder<span class="sc">$</span>state_low,</span>
<span id="cb37-59"><a href="function-approximation-and-feature-engineering.html#cb37-59" tabindex="-1"></a>      <span class="at">ylim =</span> tile_coder<span class="sc">$</span>state_high,</span>
<span id="cb37-60"><a href="function-approximation-and-feature-engineering.html#cb37-60" tabindex="-1"></a>      <span class="at">expand =</span> <span class="cn">FALSE</span></span>
<span id="cb37-61"><a href="function-approximation-and-feature-engineering.html#cb37-61" tabindex="-1"></a>    )</span>
<span id="cb37-62"><a href="function-approximation-and-feature-engineering.html#cb37-62" tabindex="-1"></a>  </span>
<span id="cb37-63"><a href="function-approximation-and-feature-engineering.html#cb37-63" tabindex="-1"></a>  <span class="co"># Add grid lines for each tiling with a unique color</span></span>
<span id="cb37-64"><a href="function-approximation-and-feature-engineering.html#cb37-64" tabindex="-1"></a>  colors <span class="ot">&lt;-</span> RColorBrewer<span class="sc">::</span><span class="fu">brewer.pal</span>(tile_coder<span class="sc">$</span>num_tilings, <span class="st">&quot;Set1&quot;</span>)</span>
<span id="cb37-65"><a href="function-approximation-and-feature-engineering.html#cb37-65" tabindex="-1"></a>  <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>tile_coder<span class="sc">$</span>num_tilings) {</span>
<span id="cb37-66"><a href="function-approximation-and-feature-engineering.html#cb37-66" tabindex="-1"></a>    p <span class="ot">&lt;-</span> p <span class="sc">+</span></span>
<span id="cb37-67"><a href="function-approximation-and-feature-engineering.html#cb37-67" tabindex="-1"></a>      <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> grids[[t]]<span class="sc">$</span>x, <span class="at">color =</span> colors[t], <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb37-68"><a href="function-approximation-and-feature-engineering.html#cb37-68" tabindex="-1"></a>      <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> grids[[t]]<span class="sc">$</span>y, <span class="at">color =</span> colors[t], <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.8</span>)</span>
<span id="cb37-69"><a href="function-approximation-and-feature-engineering.html#cb37-69" tabindex="-1"></a>  }</span>
<span id="cb37-70"><a href="function-approximation-and-feature-engineering.html#cb37-70" tabindex="-1"></a>  </span>
<span id="cb37-71"><a href="function-approximation-and-feature-engineering.html#cb37-71" tabindex="-1"></a>  <span class="co"># Highlight the active tile for each tiling</span></span>
<span id="cb37-72"><a href="function-approximation-and-feature-engineering.html#cb37-72" tabindex="-1"></a>  <span class="cf">if</span> (<span class="sc">!</span><span class="fu">is.null</span>(state)) {</span>
<span id="cb37-73"><a href="function-approximation-and-feature-engineering.html#cb37-73" tabindex="-1"></a>    active_tiles_indices <span class="ot">&lt;-</span> tile_coder<span class="sc">$</span><span class="fu">get_active_tiles</span>(state)</span>
<span id="cb37-74"><a href="function-approximation-and-feature-engineering.html#cb37-74" tabindex="-1"></a>    <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>tile_coder<span class="sc">$</span>num_tilings) {</span>
<span id="cb37-75"><a href="function-approximation-and-feature-engineering.html#cb37-75" tabindex="-1"></a>      tile_xmin <span class="ot">&lt;-</span> tile_coder<span class="sc">$</span>state_low[<span class="dv">1</span>] <span class="sc">+</span> active_tiles_indices[[t]][<span class="dv">1</span>] <span class="sc">*</span> tile_coder<span class="sc">$</span>tile_widths[<span class="dv">1</span>] <span class="sc">-</span> tile_coder<span class="sc">$</span>offsets[t, <span class="dv">1</span>]</span>
<span id="cb37-76"><a href="function-approximation-and-feature-engineering.html#cb37-76" tabindex="-1"></a>      tile_ymin <span class="ot">&lt;-</span> tile_coder<span class="sc">$</span>state_low[<span class="dv">2</span>] <span class="sc">+</span> active_tiles_indices[[t]][<span class="dv">2</span>] <span class="sc">*</span> tile_coder<span class="sc">$</span>tile_widths[<span class="dv">2</span>] <span class="sc">-</span> tile_coder<span class="sc">$</span>offsets[t, <span class="dv">2</span>]</span>
<span id="cb37-77"><a href="function-approximation-and-feature-engineering.html#cb37-77" tabindex="-1"></a>      </span>
<span id="cb37-78"><a href="function-approximation-and-feature-engineering.html#cb37-78" tabindex="-1"></a>      p <span class="ot">&lt;-</span> p <span class="sc">+</span> <span class="fu">annotate</span>(</span>
<span id="cb37-79"><a href="function-approximation-and-feature-engineering.html#cb37-79" tabindex="-1"></a>        <span class="st">&quot;rect&quot;</span>,</span>
<span id="cb37-80"><a href="function-approximation-and-feature-engineering.html#cb37-80" tabindex="-1"></a>        <span class="at">xmin =</span> tile_xmin,</span>
<span id="cb37-81"><a href="function-approximation-and-feature-engineering.html#cb37-81" tabindex="-1"></a>        <span class="at">xmax =</span> tile_xmin <span class="sc">+</span> tile_coder<span class="sc">$</span>tile_widths[<span class="dv">1</span>],</span>
<span id="cb37-82"><a href="function-approximation-and-feature-engineering.html#cb37-82" tabindex="-1"></a>        <span class="at">ymin =</span> tile_ymin,</span>
<span id="cb37-83"><a href="function-approximation-and-feature-engineering.html#cb37-83" tabindex="-1"></a>        <span class="at">ymax =</span> tile_ymin <span class="sc">+</span> tile_coder<span class="sc">$</span>tile_widths[<span class="dv">2</span>],</span>
<span id="cb37-84"><a href="function-approximation-and-feature-engineering.html#cb37-84" tabindex="-1"></a>        <span class="at">fill =</span> colors[t], <span class="at">alpha =</span> <span class="fl">0.3</span>, <span class="at">color =</span> colors[t], <span class="at">size =</span> <span class="fl">1.2</span></span>
<span id="cb37-85"><a href="function-approximation-and-feature-engineering.html#cb37-85" tabindex="-1"></a>      )</span>
<span id="cb37-86"><a href="function-approximation-and-feature-engineering.html#cb37-86" tabindex="-1"></a>    }</span>
<span id="cb37-87"><a href="function-approximation-and-feature-engineering.html#cb37-87" tabindex="-1"></a>    p <span class="ot">&lt;-</span> p <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x =</span> state[<span class="dv">1</span>], <span class="at">y =</span> state[<span class="dv">2</span>]), <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">size =</span> <span class="dv">5</span>, <span class="at">shape =</span> <span class="dv">17</span>)</span>
<span id="cb37-88"><a href="function-approximation-and-feature-engineering.html#cb37-88" tabindex="-1"></a>  }</span>
<span id="cb37-89"><a href="function-approximation-and-feature-engineering.html#cb37-89" tabindex="-1"></a>  </span>
<span id="cb37-90"><a href="function-approximation-and-feature-engineering.html#cb37-90" tabindex="-1"></a>  p <span class="sc">+</span> <span class="fu">labs</span>(</span>
<span id="cb37-91"><a href="function-approximation-and-feature-engineering.html#cb37-91" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;Tile Coding&quot;</span>,</span>
<span id="cb37-92"><a href="function-approximation-and-feature-engineering.html#cb37-92" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="fu">paste</span>(tile_coder<span class="sc">$</span>num_tilings, <span class="st">&quot;Overlapping Tilings&quot;</span>),</span>
<span id="cb37-93"><a href="function-approximation-and-feature-engineering.html#cb37-93" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;State Dimension 1&quot;</span>,</span>
<span id="cb37-94"><a href="function-approximation-and-feature-engineering.html#cb37-94" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;State Dimension 2&quot;</span></span>
<span id="cb37-95"><a href="function-approximation-and-feature-engineering.html#cb37-95" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb37-96"><a href="function-approximation-and-feature-engineering.html#cb37-96" tabindex="-1"></a>    <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">14</span>)</span>
<span id="cb37-97"><a href="function-approximation-and-feature-engineering.html#cb37-97" tabindex="-1"></a>}</span>
<span id="cb37-98"><a href="function-approximation-and-feature-engineering.html#cb37-98" tabindex="-1"></a></span>
<span id="cb37-99"><a href="function-approximation-and-feature-engineering.html#cb37-99" tabindex="-1"></a><span class="co"># Example Usage</span></span>
<span id="cb37-100"><a href="function-approximation-and-feature-engineering.html#cb37-100" tabindex="-1"></a>tile_coder_2d <span class="ot">&lt;-</span> <span class="fu">create_tile_coder</span>(</span>
<span id="cb37-101"><a href="function-approximation-and-feature-engineering.html#cb37-101" tabindex="-1"></a>  <span class="at">state_low =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>),</span>
<span id="cb37-102"><a href="function-approximation-and-feature-engineering.html#cb37-102" tabindex="-1"></a>  <span class="at">state_high =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">10</span>),</span>
<span id="cb37-103"><a href="function-approximation-and-feature-engineering.html#cb37-103" tabindex="-1"></a>  <span class="at">num_tilings =</span> <span class="dv">4</span>,</span>
<span id="cb37-104"><a href="function-approximation-and-feature-engineering.html#cb37-104" tabindex="-1"></a>  <span class="at">tiles_per_dim =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">5</span>)</span>
<span id="cb37-105"><a href="function-approximation-and-feature-engineering.html#cb37-105" tabindex="-1"></a>)</span>
<span id="cb37-106"><a href="function-approximation-and-feature-engineering.html#cb37-106" tabindex="-1"></a><span class="fu">visualize_tile_coding</span>(tile_coder_2d, <span class="at">state =</span> <span class="fu">c</span>(<span class="fl">3.2</span>, <span class="fl">7.8</span>))</span></code></pre></div>
</div>
<div id="radial-basis-functions-rbfs" class="section level3 hasAnchor" number="11.3.3">
<h3><span class="header-section-number">11.3.3</span> Radial Basis Functions (RBFs)<a href="function-approximation-and-feature-engineering.html#radial-basis-functions-rbfs" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Radial Basis Functions (RBFs)</strong> are smooth, continuous basis functions that produce a graded response based on the distance to a center point. The most common form is the Gaussian RBF:</p>
<p><span class="math display">\[\phi_i(s) = \exp\left(-\frac{\|s - c_i\|^2}{2\sigma_i^2}\right)\]</span></p>
<p>Here, <span class="math inline">\(c\_i\)</span> is the center of the <span class="math inline">\(i\)</span>-th RBF and <span class="math inline">\(\\sigma\_i\)</span> is its width (or bandwidth). Unlike binary features, RBFs provide a continuous measure of similarity. The width <span class="math inline">\(\\sigma\)</span> controls the locality of influence: a small <span class="math inline">\(\\sigma\)</span> creates a “spiky” function with local generalization, while a large <span class="math inline">\(\\sigma\)</span> creates a smooth function with broad generalization.</p>
<p>RBF networks are <strong>universal approximators</strong>, meaning they can represent any continuous function with arbitrary accuracy, given enough basis functions. The placement of centers and choice of widths are critical. Centers can be placed on a fixed grid, randomly, or adapted during learning using techniques like k-means clustering on experienced states.</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="function-approximation-and-feature-engineering.html#cb38-1" tabindex="-1"></a><span class="co"># --- Radial Basis Function (RBF) Implementation ---</span></span>
<span id="cb38-2"><a href="function-approximation-and-feature-engineering.html#cb38-2" tabindex="-1"></a>create_rbf_network <span class="ot">&lt;-</span> <span class="cf">function</span>(centers, sigmas) {</span>
<span id="cb38-3"><a href="function-approximation-and-feature-engineering.html#cb38-3" tabindex="-1"></a>  <span class="cf">if</span> (<span class="fu">is.vector</span>(sigmas)) {</span>
<span id="cb38-4"><a href="function-approximation-and-feature-engineering.html#cb38-4" tabindex="-1"></a>    sigmas <span class="ot">&lt;-</span> <span class="fu">rep</span>(sigmas[<span class="dv">1</span>], <span class="fu">nrow</span>(centers))</span>
<span id="cb38-5"><a href="function-approximation-and-feature-engineering.html#cb38-5" tabindex="-1"></a>  }</span>
<span id="cb38-6"><a href="function-approximation-and-feature-engineering.html#cb38-6" tabindex="-1"></a>  </span>
<span id="cb38-7"><a href="function-approximation-and-feature-engineering.html#cb38-7" tabindex="-1"></a>  compute_features <span class="ot">&lt;-</span> <span class="cf">function</span>(state) {</span>
<span id="cb38-8"><a href="function-approximation-and-feature-engineering.html#cb38-8" tabindex="-1"></a>    state_vec <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(state)</span>
<span id="cb38-9"><a href="function-approximation-and-feature-engineering.html#cb38-9" tabindex="-1"></a>    distances_sq <span class="ot">&lt;-</span> <span class="fu">colSums</span>((<span class="fu">t</span>(centers) <span class="sc">-</span> state_vec)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb38-10"><a href="function-approximation-and-feature-engineering.html#cb38-10" tabindex="-1"></a>    features <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="sc">-</span>distances_sq <span class="sc">/</span> (<span class="dv">2</span> <span class="sc">*</span> sigmas<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb38-11"><a href="function-approximation-and-feature-engineering.html#cb38-11" tabindex="-1"></a>    <span class="fu">return</span>(features)</span>
<span id="cb38-12"><a href="function-approximation-and-feature-engineering.html#cb38-12" tabindex="-1"></a>  }</span>
<span id="cb38-13"><a href="function-approximation-and-feature-engineering.html#cb38-13" tabindex="-1"></a>  </span>
<span id="cb38-14"><a href="function-approximation-and-feature-engineering.html#cb38-14" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(</span>
<span id="cb38-15"><a href="function-approximation-and-feature-engineering.html#cb38-15" tabindex="-1"></a>    <span class="at">compute_features =</span> compute_features,</span>
<span id="cb38-16"><a href="function-approximation-and-feature-engineering.html#cb38-16" tabindex="-1"></a>    <span class="at">centers =</span> centers,</span>
<span id="cb38-17"><a href="function-approximation-and-feature-engineering.html#cb38-17" tabindex="-1"></a>    <span class="at">sigmas =</span> sigmas</span>
<span id="cb38-18"><a href="function-approximation-and-feature-engineering.html#cb38-18" tabindex="-1"></a>  ))</span>
<span id="cb38-19"><a href="function-approximation-and-feature-engineering.html#cb38-19" tabindex="-1"></a>}</span>
<span id="cb38-20"><a href="function-approximation-and-feature-engineering.html#cb38-20" tabindex="-1"></a></span>
<span id="cb38-21"><a href="function-approximation-and-feature-engineering.html#cb38-21" tabindex="-1"></a><span class="co"># --- Visualization Function for RBF Network Activation ---</span></span>
<span id="cb38-22"><a href="function-approximation-and-feature-engineering.html#cb38-22" tabindex="-1"></a>visualize_rbf_activation <span class="ot">&lt;-</span> <span class="cf">function</span>(rbf_network, state_dims) {</span>
<span id="cb38-23"><a href="function-approximation-and-feature-engineering.html#cb38-23" tabindex="-1"></a>  <span class="co"># Create a grid of points to evaluate the RBF network</span></span>
<span id="cb38-24"><a href="function-approximation-and-feature-engineering.html#cb38-24" tabindex="-1"></a>  grid_df <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(</span>
<span id="cb38-25"><a href="function-approximation-and-feature-engineering.html#cb38-25" tabindex="-1"></a>    <span class="at">x =</span> <span class="fu">seq</span>(<span class="dv">0</span>, state_dims[<span class="dv">1</span>], <span class="at">length.out =</span> <span class="dv">100</span>),</span>
<span id="cb38-26"><a href="function-approximation-and-feature-engineering.html#cb38-26" tabindex="-1"></a>    <span class="at">y =</span> <span class="fu">seq</span>(<span class="dv">0</span>, state_dims[<span class="dv">2</span>], <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb38-27"><a href="function-approximation-and-feature-engineering.html#cb38-27" tabindex="-1"></a>  )</span>
<span id="cb38-28"><a href="function-approximation-and-feature-engineering.html#cb38-28" tabindex="-1"></a>  </span>
<span id="cb38-29"><a href="function-approximation-and-feature-engineering.html#cb38-29" tabindex="-1"></a>  <span class="co"># Calculate the sum of all RBF activations at each grid point</span></span>
<span id="cb38-30"><a href="function-approximation-and-feature-engineering.html#cb38-30" tabindex="-1"></a>  activations <span class="ot">&lt;-</span> <span class="fu">apply</span>(grid_df, <span class="dv">1</span>, <span class="cf">function</span>(point) {</span>
<span id="cb38-31"><a href="function-approximation-and-feature-engineering.html#cb38-31" tabindex="-1"></a>    <span class="fu">sum</span>(rbf_network<span class="sc">$</span><span class="fu">compute_features</span>(point))</span>
<span id="cb38-32"><a href="function-approximation-and-feature-engineering.html#cb38-32" tabindex="-1"></a>  })</span>
<span id="cb38-33"><a href="function-approximation-and-feature-engineering.html#cb38-33" tabindex="-1"></a>  grid_df<span class="sc">$</span>activation <span class="ot">&lt;-</span> activations</span>
<span id="cb38-34"><a href="function-approximation-and-feature-engineering.html#cb38-34" tabindex="-1"></a>  </span>
<span id="cb38-35"><a href="function-approximation-and-feature-engineering.html#cb38-35" tabindex="-1"></a>  <span class="fu">ggplot</span>(grid_df, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y, <span class="at">fill =</span> activation)) <span class="sc">+</span></span>
<span id="cb38-36"><a href="function-approximation-and-feature-engineering.html#cb38-36" tabindex="-1"></a>    <span class="fu">geom_raster</span>(<span class="at">interpolate =</span> <span class="cn">TRUE</span>) <span class="sc">+</span></span>
<span id="cb38-37"><a href="function-approximation-and-feature-engineering.html#cb38-37" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">data =</span> <span class="fu">as.data.frame</span>(rbf_network<span class="sc">$</span>centers), <span class="fu">aes</span>(<span class="at">x =</span> V1, <span class="at">y =</span> V2), </span>
<span id="cb38-38"><a href="function-approximation-and-feature-engineering.html#cb38-38" tabindex="-1"></a>               <span class="at">color =</span> <span class="st">&quot;white&quot;</span>, <span class="at">shape =</span> <span class="dv">3</span>, <span class="at">size =</span> <span class="dv">2</span>, <span class="at">alpha =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb38-39"><a href="function-approximation-and-feature-engineering.html#cb38-39" tabindex="-1"></a>    <span class="fu">scale_fill_viridis_c</span>(<span class="at">name =</span> <span class="st">&quot;Total</span><span class="sc">\n</span><span class="st">Activation&quot;</span>) <span class="sc">+</span></span>
<span id="cb38-40"><a href="function-approximation-and-feature-engineering.html#cb38-40" tabindex="-1"></a>    <span class="fu">coord_fixed</span>(<span class="at">expand =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb38-41"><a href="function-approximation-and-feature-engineering.html#cb38-41" tabindex="-1"></a>    <span class="fu">labs</span>(</span>
<span id="cb38-42"><a href="function-approximation-and-feature-engineering.html#cb38-42" tabindex="-1"></a>      <span class="at">title =</span> <span class="st">&quot;Radial Basis Function Network Activation&quot;</span>,</span>
<span id="cb38-43"><a href="function-approximation-and-feature-engineering.html#cb38-43" tabindex="-1"></a>      <span class="at">subtitle =</span> <span class="st">&quot;White crosses indicate RBF centers&quot;</span>,</span>
<span id="cb38-44"><a href="function-approximation-and-feature-engineering.html#cb38-44" tabindex="-1"></a>      <span class="at">x =</span> <span class="st">&quot;State Dimension 1&quot;</span>,</span>
<span id="cb38-45"><a href="function-approximation-and-feature-engineering.html#cb38-45" tabindex="-1"></a>      <span class="at">y =</span> <span class="st">&quot;State Dimension 2&quot;</span></span>
<span id="cb38-46"><a href="function-approximation-and-feature-engineering.html#cb38-46" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb38-47"><a href="function-approximation-and-feature-engineering.html#cb38-47" tabindex="-1"></a>    <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">14</span>)</span>
<span id="cb38-48"><a href="function-approximation-and-feature-engineering.html#cb38-48" tabindex="-1"></a>}</span>
<span id="cb38-49"><a href="function-approximation-and-feature-engineering.html#cb38-49" tabindex="-1"></a></span>
<span id="cb38-50"><a href="function-approximation-and-feature-engineering.html#cb38-50" tabindex="-1"></a><span class="co"># Example Usage</span></span>
<span id="cb38-51"><a href="function-approximation-and-feature-engineering.html#cb38-51" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb38-52"><a href="function-approximation-and-feature-engineering.html#cb38-52" tabindex="-1"></a>rbf_centers <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(<span class="dv">20</span>, <span class="dv">0</span>, <span class="dv">10</span>), <span class="at">nrow =</span> <span class="dv">10</span>, <span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb38-53"><a href="function-approximation-and-feature-engineering.html#cb38-53" tabindex="-1"></a>rbf_sigmas <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fl">2.0</span>, <span class="dv">10</span>) <span class="co"># Uniform width for all RBFs</span></span>
<span id="cb38-54"><a href="function-approximation-and-feature-engineering.html#cb38-54" tabindex="-1"></a>rbf_net <span class="ot">&lt;-</span> <span class="fu">create_rbf_network</span>(<span class="at">centers =</span> rbf_centers, <span class="at">sigmas =</span> rbf_sigmas)</span>
<span id="cb38-55"><a href="function-approximation-and-feature-engineering.html#cb38-55" tabindex="-1"></a></span>
<span id="cb38-56"><a href="function-approximation-and-feature-engineering.html#cb38-56" tabindex="-1"></a><span class="fu">visualize_rbf_activation</span>(rbf_net, <span class="at">state_dims =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span></code></pre></div>
<p>The choice of basis function depends on the problem, computational budget, and desired generalization properties.</p>
<ul>
<li><strong>Computational Efficiency</strong>: <strong>Tile coding</strong> is often the fastest, as it involves simple arithmetic and guarantees a fixed, small number of active features. Coarse coding can be slower if it requires checking against many overlapping regions. RBFs are typically the most expensive, as they require distance calculations to all centers.</li>
<li><strong>Memory Requirements</strong>: A tile coder with <span class="math inline">\(N\)</span> tilings and <span class="math inline">\(T\)</span> tiles per tiling has <span class="math inline">\(N \\times T\)</span> features. RBFs require storing all centers and widths. The memory footprint depends on the number of basis functions needed for the desired accuracy.</li>
<li><strong>Generalization Control</strong>: <strong>RBFs</strong> offer the most fine-grained control over generalization through the placement of centers and tuning of widths. <strong>Tile coding</strong> provides structured, axis-aligned generalization controlled by the number and shape of tiles. <strong>Coarse coding</strong> is the most straightforward but offers the least precise control.</li>
<li><strong>Ease of Use</strong>: Tile coding is often a strong default choice for low-to-medium dimensional control problems due to its computational efficiency and robust performance with minimal tuning.</li>
</ul>
<p>Linear function approximation and classical basis functions are not merely historical footnotes; they are the conceptual foundation upon which deep RL is built. They provide a clear and analyzable framework for understanding the core challenge of RL: balancing discrimination and generalization. The principles of feature design, the mathematics of TD updates, and the properties of different basis functions offer crucial insights that remain relevant when designing, training, and debugging complex neural network architectures.</p>
<p>Mastering these fundamentals provides the intuition needed to navigate the complexities of modern RL. The journey from tabular methods to deep learning necessarily passes through this foundational territory, making it essential knowledge for any serious RL practitioner.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="dyna-q-enhanced-exploration-in-integrated-learning-and-planning.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="learning-policies-versus-learning-values.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/Kamran-Afzali/Bookdown_RLR/edit/main/11-Functions_Features.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": "https://github.com/Kamran-Afzali/Bookdown_RLR/blob/main/11-Functions_Features.Rmd",
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

understanding-reinforcement-learning-from-bandits-to-policy-optimization
introduction-to-reinforcement-learning
the-multi-armed-bandit-the-simplest-case
transition-to-markov-decision-processes
comparing-reinforcement-learning-methods
dynamic-programming-model-based-learning
model-free-approaches-monte-carlo-and-td-learning
q-learning-and-function-approximation
policy-gradient-and-actor-critic-methods
advanced-policy-optimization-techniques
conclusion-and-further-directions
references
the-multi-armed-bandit-problem
introduction
mathematical-formalism
frequentist-approach-ucb1-algorithm
r-code-for-ucb1
bayesian-approach-thompson-sampling
r-code-for-thompson-sampling
epsilon-greedy-strategy
r-code-for-epsilon-greedy
summary-table
conclusion
markov-decision-processes-and-dynamic-programming
introduction-1
constructing-the-mdp-in-r
value-iteration-algorithm
evaluation-and-interpretation
theoretical-properties-of-value-iteration
summary-table-1
conclusion-1
